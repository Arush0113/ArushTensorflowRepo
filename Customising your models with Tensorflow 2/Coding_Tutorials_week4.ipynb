{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "colab": {
      "name": "Coding Tutorial.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "VpP1Hhzsg8Wc",
        "ahoOUuPyg8Wf",
        "PodDiOpqg8Wg",
        "iJSeMwsYg8Wh",
        "nykL0bnsg8Wl",
        "WLrEfECWg8Wm",
        "0aXu7aDYg8Wp",
        "IWq6cz0Vg8Wq",
        "WfkcKGoCg8Wq",
        "Oq178tw-g8Ws"
      ],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Arush0113/ArushTensorflowRepo/blob/main/Customising%20your%20models%20with%20Tensorflow%202/Coding_Tutorials_week4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t5GxGXeJg8V1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "724b5f68-6d22-48b4-d7d8-d8a8d93d2a9e"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.4.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VJpZbfyDg8V7"
      },
      "source": [
        "# Model subclassing and custom training loops"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FXK34vjDhZNI",
        "outputId": "dd4da3a4-c51c-4d31-c338-8f50556e156b"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XLJUdDNzg8V8"
      },
      "source": [
        " ## Coding tutorials\n",
        " #### [1. Model subclassing](#coding_tutorial_1)\n",
        " #### [2. Custom layers](#coding_tutorial_2)\n",
        " #### [3. Automatic differentiation](#coding_tutorial_3)\n",
        " #### [4. Custom training loops](#coding_tutorial_4)\n",
        " #### [5. tf.function decorator](#coding_tutorial_5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xpIWbZECg8V-"
      },
      "source": [
        "***\n",
        "<a id=\"coding_tutorial_1\"></a>\n",
        "## Model subclassing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U566hQoRg8V_"
      },
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, Dropout, Softmax, concatenate"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jae3y8mFg8WA"
      },
      "source": [
        "#### Create a simple model using the model subclassing API"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jmy8NwR5g8WA"
      },
      "source": [
        "# Build the model\n",
        "\n",
        "class MyModel(Model):\n",
        "\n",
        "  def __init__(self):\n",
        "    super(MyModel, self).__init__()\n",
        "    self.dense_1 = Dense(64, activation='relu')\n",
        "    self.dense_2 = Dense(10)\n",
        "    self.dropout = Dropout(0.4)\n",
        "\n",
        "  def call(self, inputs, training = True):\n",
        "    x = self.dense_1(inputs)\n",
        "    if training:\n",
        "      x = self.dropout(x)\n",
        "    return self.dense_2(x)"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zNTAZ8ZBg8WB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0a4a279-5d9c-4d5e-cd70-0947d86b4daf"
      },
      "source": [
        "# Print the model summary\n",
        "model = MyModel()\n",
        "model(tf.random.uniform([1,10]))\n",
        "model.summary()"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"my_model_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_5 (Dense)              multiple                  704       \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              multiple                  650       \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          multiple                  0         \n",
            "=================================================================\n",
            "Total params: 1,354\n",
            "Trainable params: 1,354\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "700xuZnKjh4b"
      },
      "source": [
        "# Build the model\n",
        "\n",
        "class MyModel(Model):\n",
        "\n",
        "  def __init__(self):\n",
        "    super(MyModel, self).__init__()\n",
        "    self.dense_1 = Dense(64, activation='relu')\n",
        "    self.dense_2 = Dense(10)\n",
        "    self.dense_3 = Dense(5)\n",
        "    self.softmax = Softmax()\n",
        "\n",
        "  def call(self, inputs,):\n",
        "    x = self.dense_1(inputs)\n",
        "    y1 = self.dense_2(inputs)\n",
        "    y2 = self.dense_3(y1)\n",
        "    concat = concatenate([x,y2])\n",
        "    \n",
        "    return self.softmax(concat)"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DKF4mg4DkQ-f",
        "outputId": "f1df9d09-e5d0-406d-9ec9-8cb9c4c77fe8"
      },
      "source": [
        "# Print the model summary\n",
        "model = MyModel()\n",
        "model(tf.random.uniform([1,10]))\n",
        "model.summary()"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"my_model_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_7 (Dense)              multiple                  704       \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              multiple                  110       \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              multiple                  55        \n",
            "_________________________________________________________________\n",
            "softmax_2 (Softmax)          multiple                  0         \n",
            "=================================================================\n",
            "Total params: 869\n",
            "Trainable params: 869\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DJlVb3Ufg8WB"
      },
      "source": [
        "***\n",
        "<a id=\"coding_tutorial_2\"></a>\n",
        "## Custom layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oLTuI0npg8WC"
      },
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Layer, Softmax"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iiKP0VUog8WC"
      },
      "source": [
        "#### Create custom layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BOslZHdYg8WD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c26eb06-56b1-47be-c4fc-27244000528b"
      },
      "source": [
        "# Create a custom layer\n",
        "\n",
        "class MyLayer(Layer):\n",
        "\n",
        "  def __init__(self, units, input_dim):\n",
        "    super(MyLayer, self).__init__()\n",
        "    self.w = self.add_weight(shape = (input_dim, units),\n",
        "                             initializer = 'random_normal')\n",
        "    self.b = self.add_weight(shape = (input_dim, units),\n",
        "                             initializer = 'random_normal')\n",
        "    \n",
        "  def call(self, inputs):\n",
        "    return tf.matmul(inputs, self.w) + self.b\n",
        "\n",
        "dense_layer = MyLayer(3,5)\n",
        "x = tf.ones((1,5))\n",
        "print(dense_layer(x))\n",
        "print(dense_layer.weights)"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[-0.06943703  0.06669079 -0.17230874]\n",
            " [-0.03467695  0.07580611 -0.18393208]\n",
            " [-0.07647724  0.08579997 -0.16436075]\n",
            " [-0.01921696  0.08406146 -0.13222769]\n",
            " [-0.05876692 -0.00539492 -0.10743168]], shape=(5, 3), dtype=float32)\n",
            "[<tf.Variable 'Variable:0' shape=(5, 3) dtype=float32, numpy=\n",
            "array([[ 0.04210454,  0.06191711, -0.03210635],\n",
            "       [ 0.00238939,  0.06195689, -0.09499218],\n",
            "       [-0.05285186, -0.04082963, -0.08217468],\n",
            "       [-0.06695555, -0.00339337, -0.01477633],\n",
            "       [ 0.05295002, -0.04072594,  0.05795218]], dtype=float32)>, <tf.Variable 'Variable:0' shape=(5, 3) dtype=float32, numpy=\n",
            "array([[-0.04707357,  0.02776573, -0.00621137],\n",
            "       [-0.0123135 ,  0.03688106, -0.0178347 ],\n",
            "       [-0.05411379,  0.04687491,  0.00173663],\n",
            "       [ 0.00314649,  0.0451364 ,  0.03386969],\n",
            "       [-0.03640347, -0.04431998,  0.05866569]], dtype=float32)>]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JMKatUweg8WF"
      },
      "source": [
        "# Specify trainable weights\n",
        "\n",
        "class MyLayer(Layer):\n",
        "\n",
        "  def __init__(self, units, input_dim):\n",
        "    super(MyLayer, self).__init__()\n",
        "    self.w = self.add_weight(shape = (input_dim, units),\n",
        "                             initializer = 'random_normal',\n",
        "                             trainable = False)\n",
        "    self.b = self.add_weight(shape = (units,),\n",
        "                             initializer = 'zeros',\n",
        "                             trainable = False)\n",
        "    \n",
        "  def call(self, inputs):\n",
        "    return tf.matmul(inputs, self.w) + self.b\n",
        "\n",
        "dense_layer = MyLayer(3,5)"
      ],
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-MP3DNSig8WF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2eafdbec-720b-4a84-d446-61b51a6c2ee3"
      },
      "source": [
        "print('trainable weights:', len(dense_layer.trainable_weights))\n",
        "print('non-trainable weights:', len(dense_layer.non_trainable_weights))"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "trainable weights: 0\n",
            "non-trainable weights: 2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CgaM7dU2g8WG"
      },
      "source": [
        "# Create a custom layer to accumulate means of output values\n",
        "\n",
        "class MyLayerMean(Layer):\n",
        "\n",
        "  def __init__(self, units, input_dim):\n",
        "    super(MyLayerMean, self).__init__()\n",
        "    self.w = self.add_weight(shape = (input_dim, units),\n",
        "                             initializer = 'random_normal')\n",
        "    self.b = self.add_weight(shape = (input_dim, units),\n",
        "                             initializer = 'random_normal')\n",
        "    self.sum_activation = tf.Variable(initial_value=tf.zeros((units,)),\n",
        "                                      trainable = False)\n",
        "    self.number_call = tf.Variable(initial_value=0,\n",
        "                                   trainable = False)\n",
        "    \n",
        "  def call(self, inputs):\n",
        "    activations = tf.matmul(inputs, self.w) + self.b\n",
        "    self.sum_activation.assign_add(tf.reduce_sum(activations, axis = 0))\n",
        "    self.number_call.assign_add(inputs.shape[0])\n",
        "    return activations, self.sum_activation/tf.cast(self.number_call, tf.float32)\n",
        "\n",
        "dense_layer = MyLayerMean(3,5)\n"
      ],
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EIifhb-1g8WH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d363106-f4fc-4b05-dbc1-9c9c454b30e0"
      },
      "source": [
        "# Test the layer\n",
        "\n",
        "y, activation_means = dense_layer(tf.ones((1, 5)))\n",
        "print(activation_means.numpy())\n",
        "\n",
        "y, activation_means = dense_layer(tf.ones((1, 5)))\n",
        "print(activation_means.numpy())"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[-0.18036649 -1.2825412  -0.00915272]\n",
            "[-0.18036649 -1.2825412  -0.00915272]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tpChFBiDg8WI"
      },
      "source": [
        "# Create a Dropout layer as a custom layer\n",
        "\n",
        "class MyDropout(Layer):\n",
        "\n",
        "    def __init__(self, rate):\n",
        "        super(MyDropout, self).__init__()\n",
        "        self.rate = rate\n",
        "        \n",
        "    def call(self, inputs):\n",
        "        # Define forward pass for dropout layer\n",
        "        return tf.nn.dropout(inputs, rate = self.rate)"
      ],
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HlS6Hrwwg8WJ"
      },
      "source": [
        "#### Implement the custom layers into a model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OjD1nFBIg8WK"
      },
      "source": [
        "# Build the model using custom layers with the model subclassing API\n",
        "\n",
        "class MyModel(Model):\n",
        "\n",
        "    def __init__(self, units_1, input_dim_1, units_2, units_3):\n",
        "        super(MyModel, self).__init__()\n",
        "        # Define layers\n",
        "        self.layer_1 = MyLayer(units_1, input_dim_1)\n",
        "        self.dropout_1 = MyDropout(0.5)\n",
        "        self.layer_2 = MyLayer(units_2, units_1)\n",
        "        self.dropout_2 = MyDropout(0.5)\n",
        "        self.layer_3 = MyLayer(units_3, units_2)\n",
        "        self.softmax = Softmax()\n",
        "           \n",
        "    def call(self, inputs):\n",
        "        # Define forward pass\n",
        "\n",
        "        x = self.layer_1(inputs)\n",
        "        x=  tf.nn.relu(x)\n",
        "        x = self.dropout_1(x)\n",
        "        x = self.layer_2(x)\n",
        "        x=  tf.nn.relu(x)\n",
        "        x = self.dropout_2(x)\n",
        "        x = self.layer_3(x)\n",
        "\n",
        "        return self.softmax(x)"
      ],
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nW_XXYZZg8WL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c696c324-89e5-43b4-cc99-b6f18db8c280"
      },
      "source": [
        "  # Instantiate a model object\n",
        "\n",
        "model = MyModel(64,10000,64,46)\n",
        "print(model(tf.ones((1, 10000))))\n",
        "model.summary()"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[0.02141337 0.00517599 0.01843137 0.02801936 0.01636618 0.01932723\n",
            "  0.00941794 0.01705426 0.0317383  0.02208736 0.01488989 0.03208938\n",
            "  0.02857926 0.02929221 0.01046696 0.00880532 0.01068847 0.03722416\n",
            "  0.0218576  0.0069334  0.03242623 0.02692416 0.00451995 0.01956953\n",
            "  0.02867604 0.02001929 0.00520878 0.00796657 0.03502599 0.00670761\n",
            "  0.01057615 0.03584002 0.01850063 0.00671961 0.01261562 0.02394462\n",
            "  0.01881378 0.04906602 0.05079688 0.07226079 0.01027133 0.04443101\n",
            "  0.0033825  0.0261287  0.01156616 0.02818411]], shape=(1, 46), dtype=float32)\n",
            "Model: \"my_model_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "my_layer_12 (MyLayer)        multiple                  640064    \n",
            "_________________________________________________________________\n",
            "my_dropout_4 (MyDropout)     multiple                  0         \n",
            "_________________________________________________________________\n",
            "my_layer_13 (MyLayer)        multiple                  4160      \n",
            "_________________________________________________________________\n",
            "my_dropout_5 (MyDropout)     multiple                  0         \n",
            "_________________________________________________________________\n",
            "my_layer_14 (MyLayer)        multiple                  2990      \n",
            "_________________________________________________________________\n",
            "softmax_4 (Softmax)          multiple                  0         \n",
            "=================================================================\n",
            "Total params: 647,214\n",
            "Trainable params: 0\n",
            "Non-trainable params: 647,214\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DX1N5j6Fg8WM"
      },
      "source": [
        "***\n",
        "<a id=\"coding_tutorial_3\"></a>\n",
        "## Automatic differentiation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zkjbbnw-g8WN"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nO1TubSLg8WO"
      },
      "source": [
        "#### Create synthetic data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YZEPNHDlg8WO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "outputId": "8dcefb65-840f-47ac-e73d-ec54e501012e"
      },
      "source": [
        "# Create data from a noise contaminated linear model\n",
        "\n",
        "def MakeNoisyData(m, b, n=20):\n",
        "    x = tf.random.uniform(shape=(n,))\n",
        "    noise = tf.random.normal(shape=(len(x),), stddev=0.1)\n",
        "    y = m * x + b + noise\n",
        "    return x, y\n",
        "\n",
        "m=1\n",
        "b=2\n",
        "x_train, y_train = MakeNoisyData(m,b)\n",
        "plt.plot(x_train, y_train, 'b.')"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fa9b737f8d0>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 96
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CjxHNAvYg8WP"
      },
      "source": [
        "#### Define a linear regression model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TLGI64Ugg8WQ"
      },
      "source": [
        "from tensorflow.keras.layers import Layer"
      ],
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4HwXeB0Cg8WR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57828fea-1d45-4e7a-b83b-ea39bb445e4b"
      },
      "source": [
        "# Build a custom layer for the linear regression model\n",
        "\n",
        "class LinearLayer(Layer):\n",
        "  def __init__(self):\n",
        "    super(LinearLayer, self).__init__()\n",
        "    self.m = self.add_weight(\n",
        "        shape = (1,),\n",
        "        initializer = 'random_normal',\n",
        "    )\n",
        "    self.b = self.add_weight(\n",
        "        shape = (1,),\n",
        "        initializer = 'zeros'\n",
        "    )\n",
        "\n",
        "  def call(self, inputs):\n",
        "    return self.m * inputs + self.b\n",
        "\n",
        "linear_regression = LinearLayer()\n",
        "\n",
        "print(linear_regression(x_train))\n",
        "print(linear_regression.weights)"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[0.00262396 0.00240553 0.00182627 0.0015534  0.00338618 0.00382298\n",
            " 0.00363204 0.00327051 0.00169631 0.00375314 0.00273156 0.00337227\n",
            " 0.00157855 0.00284328 0.00381082 0.00251736 0.00119584 0.00199243\n",
            " 0.00325853 0.00019704], shape=(20,), dtype=float32)\n",
            "[<tf.Variable 'Variable:0' shape=(1,) dtype=float32, numpy=array([0.00398529], dtype=float32)>, <tf.Variable 'Variable:0' shape=(1,) dtype=float32, numpy=array([0.], dtype=float32)>]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R9jZymCV1ylE",
        "outputId": "55ca9bae-efbc-4fc2-d5d6-2c8da6bfad9e"
      },
      "source": [
        "print(np.random.randn(5,))\n",
        "print(np.random.randn(5,1))\n",
        "print(np.random.randn(1,5))"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[-0.14168079 -0.26457106  0.91878852 -0.77658986 -0.770842  ]\n",
            "[[-0.48499173]\n",
            " [ 0.32532766]\n",
            " [-1.0262912 ]\n",
            " [-0.05878749]\n",
            " [-1.1072325 ]]\n",
            "[[ 1.17220288 -2.33934624  1.26386042  2.38317222  0.60423803]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3AqcFGwFg8WS"
      },
      "source": [
        "#### Define the loss function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "grT14aF8g8WT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44d9477a-539f-46c8-c768-9df0b2177d47"
      },
      "source": [
        "# Define the mean squared error loss function\n",
        "\n",
        "def SquaredError(y_pred, y_true):\n",
        "    return tf.reduce_mean(tf.square(y_pred - y_true)) \n",
        "\n",
        "starting_loss = SquaredError(linear_regression(x_train), y_train)\n",
        "print(\"Starting loss\", starting_loss.numpy())"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting loss 6.9796205\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fMJ7rn_gg8WU"
      },
      "source": [
        "#### Train and plot the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "INMQgrw3g8WU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "132750c9-bef1-4adb-cb57-e2ee4800da22"
      },
      "source": [
        "# Implement a gradient descent training loop for the linear regression model\n",
        "\n",
        "learning_rate = 0.05\n",
        "steps = 31\n",
        "\n",
        "for i in range(steps):\n",
        "\n",
        "  with tf.GradientTape() as tape:\n",
        "    predictions = linear_regression(x_train)\n",
        "    loss = SquaredError(predictions, y_train)\n",
        "\n",
        "  gradients = tape.gradient(loss, linear_regression.trainable_variables)\n",
        "\n",
        "  linear_regression.m.assign_sub(learning_rate * gradients[0])\n",
        "  linear_regression.b.assign_sub(learning_rate * gradients[1])\n",
        "\n",
        "  print(\"Step %d, Loss %f\" % (i, loss.numpy()))"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Step 0, Loss 6.979620\n",
            "Step 1, Loss 5.123182\n",
            "Step 2, Loss 3.761407\n",
            "Step 3, Loss 2.762486\n",
            "Step 4, Loss 2.029733\n",
            "Step 5, Loss 1.492224\n",
            "Step 6, Loss 1.097933\n",
            "Step 7, Loss 0.808698\n",
            "Step 8, Loss 0.596526\n",
            "Step 9, Loss 0.440883\n",
            "Step 10, Loss 0.326705\n",
            "Step 11, Loss 0.242944\n",
            "Step 12, Loss 0.181495\n",
            "Step 13, Loss 0.136413\n",
            "Step 14, Loss 0.103336\n",
            "Step 15, Loss 0.079066\n",
            "Step 16, Loss 0.061256\n",
            "Step 17, Loss 0.048184\n",
            "Step 18, Loss 0.038589\n",
            "Step 19, Loss 0.031544\n",
            "Step 20, Loss 0.026369\n",
            "Step 21, Loss 0.022567\n",
            "Step 22, Loss 0.019771\n",
            "Step 23, Loss 0.017713\n",
            "Step 24, Loss 0.016197\n",
            "Step 25, Loss 0.015079\n",
            "Step 26, Loss 0.014252\n",
            "Step 27, Loss 0.013639\n",
            "Step 28, Loss 0.013183\n",
            "Step 29, Loss 0.012843\n",
            "Step 30, Loss 0.012586\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b1WCRdLtg8WV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "outputId": "4522cef2-d25f-4169-b124-199be00adb09"
      },
      "source": [
        "# Plot the learned regression model\n",
        "\n",
        "print(\"m:{},  trained m:{}\".format(m,linear_regression.m.numpy()))\n",
        "print(\"b:{},  trained b:{}\".format(b,linear_regression.b.numpy()))\n",
        "\n",
        "plt.plot(x_train, y_train, 'b.')\n",
        "\n",
        "x_linear_regression=np.linspace(min(x_train), max(x_train),50)\n",
        "plt.plot(x_linear_regression, linear_regression.m*x_linear_regression+linear_regression.b, 'r.')"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "m:1,  trained m:[1.1955421]\n",
            "b:2,  trained b:[1.8319504]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fa9b6ed5a10>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 102
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qLYQ6_I3g8WW"
      },
      "source": [
        "***\n",
        "<a id=\"coding_tutorial_4\"></a>\n",
        "## Custom training loops"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JgI2cAMwg8WX"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import time"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nLLiPkKzg8WX"
      },
      "source": [
        "#### Build the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "79GCWmR3g8WZ"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Layer, Softmax"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IAKP-vy2g8WZ"
      },
      "source": [
        "# Define the custom layers and model\n",
        "\n",
        "class MyLayer(Layer):\n",
        "\n",
        "  def __init__(self, units):\n",
        "    super(MyLayer, self).__init__()\n",
        "    self.units = units\n",
        "\n",
        "  def build(self, input_shape):\n",
        "    self.w = self.add_weight(\n",
        "        shape = (input_dim, self.units),\n",
        "        initializer = 'random_Normal',\n",
        "        name = 'kernel',\n",
        "    )\n",
        "    self.b = self.add_weight(\n",
        "        shape = (self.units,),\n",
        "        initializer = 'zeros',\n",
        "        name = 'bias',\n",
        "    )\n",
        "\n",
        "    def call(self, inputs):\n",
        "      return tf.matmul(inputs, self.w) + self.b\n",
        "\n",
        "\n",
        "class MyDropout(Layer):\n",
        "\n",
        "  def __init__(self, rate):\n",
        "    super(MyDropout, self).__init__()\n",
        "    self.rate = rate\n",
        "\n",
        "  def call(self, inputs):\n",
        "    return tf.nn.dropout(inputs, self.rate)\n",
        "\n",
        "\n",
        "class MyModel(Model):\n",
        "  def __init__(self, units_1, units_2, units_3):\n",
        "    super(MyModel, self).__init__()\n",
        "\n",
        "    self.layer_1 = MyLayer(units_1)\n",
        "    self.dropout_1 = MyDropout(0.5)\n",
        "    self.layer_2 = MyLayer(units_2)\n",
        "    self.dropout_2 = MyDropout(0.5)\n",
        "    self.layer_3 = MyLayer(units_3)\n",
        "    self.softmax = Softmax()\n",
        "\n",
        "  def call(self, inputs):\n",
        "    x = self.layer_1(inputs)\n",
        "    x = tf.nn.relu(x)\n",
        "    x = self.dropout_1(x)\n",
        "    x = self.layer_2(x)\n",
        "    x = tf.nn.relu(x)\n",
        "    x = self.dropout_2(x)\n",
        "    x = self.layer_3(x)\n",
        "    return self.softmax(x)\n",
        "\n",
        "\n",
        "model = MyModel(64,64,46)\n",
        "# model.summary()"
      ],
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dUlzjE53g8Wa"
      },
      "source": [
        "#### Load the reuters dataset and define the class_names "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yqZ3efmNg8Wa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2530272-bd1d-4ed4-a529-6eb504524549"
      },
      "source": [
        "# Load the dataset\n",
        "\n",
        "from tensorflow.keras.datasets import reuters\n",
        "\n",
        "(train_data, train_labels), (test_data, test_labels) = reuters.load_data(num_words=10000)\n",
        "\n",
        "class_names = ['cocoa','grain','veg-oil','earn','acq','wheat','copper','housing','money-supply',\n",
        "   'coffee','sugar','trade','reserves','ship','cotton','carcass','crude','nat-gas',\n",
        "   'cpi','money-fx','interest','gnp','meal-feed','alum','oilseed','gold','tin',\n",
        "   'strategic-metal','livestock','retail','ipi','iron-steel','rubber','heat','jobs',\n",
        "   'lei','bop','zinc','orange','pet-chem','dlr','gas','silver','wpi','hog','lead']"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/reuters.py:148: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/reuters.py:149: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ghNqiB8Ag8Wc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6464c51a-60e8-45d5-b486-9fb2231bf7e0"
      },
      "source": [
        "# Print the class of the first sample\n",
        "\n",
        "print(\"Label: {}\".format(class_names[train_labels[0]]))"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Label: earn\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VpP1Hhzsg8Wc"
      },
      "source": [
        "#### Get the dataset word index"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o9guyqv3g8Wd"
      },
      "source": [
        "# Load the Reuters word index\n",
        "\n",
        "word_to_index = reuters.get_word_index()\n",
        "\n",
        "invert_word_index = dict([(value, key) for (key, value) in word_to_index.items()])\n",
        "text_news = ' '.join([invert_word_index.get(i - 3, '?') for i in train_data[0]])"
      ],
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dJNh3LEkg8We",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "c633b728-b728-4084-e849-8723804a0ff4"
      },
      "source": [
        "# Print the first data example sentence\n",
        "\n",
        "text_news"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'? ? ? said as a result of its december acquisition of space co it expects earnings per share in 1987 of 1 15 to 1 30 dlrs per share up from 70 cts in 1986 the company said pretax net should rise to nine to 10 mln dlrs from six mln dlrs in 1986 and rental operation revenues to 19 to 22 mln dlrs from 12 5 mln dlrs it said cash flow per share this year should be 2 50 to three dlrs reuter 3'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ahoOUuPyg8Wf"
      },
      "source": [
        "#### Preprocess the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gXClGfGkg8Wf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1c6e469-cf78-417a-b6af-992b6407adf3"
      },
      "source": [
        "# Define a function that encodes the data into a 'bag of words' representation\n",
        "\n",
        "def bag_of_words(text_samples, elements=10000):\n",
        "    output = np.zeros((len(text_samples), elements))\n",
        "    for i, word in enumerate(text_samples):\n",
        "        output[i, word] = 1.\n",
        "    return output\n",
        "\n",
        "x_train = bag_of_words(train_data)\n",
        "x_test = bag_of_words(test_data)\n",
        "\n",
        "print(\"Shape of x_train:\", x_train.shape)\n",
        "print(\"Shape of x_test:\", x_test.shape)\n",
        "x_train[0]"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of x_train: (8982, 10000)\n",
            "Shape of x_test: (2246, 10000)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 1., 1., ..., 0., 0., 0.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HGwk9tDLKDl8"
      },
      "source": [
        "# output = np.zeros((len(sample_data), 10000))\n",
        "# sample_data = train_data[:20]\n",
        "# # print(output)\n",
        "# for i, word in enumerate(sample_data):\n",
        "#   # print(word)\n",
        "#   output[i, word] = 1\n",
        "# output.shape"
      ],
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PodDiOpqg8Wg"
      },
      "source": [
        "#### Define the loss function and optimizer\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WLvLTYnLg8Wh"
      },
      "source": [
        "# Define the categorical cross entropy loss and Adam optimizer\n",
        "\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy()\n",
        "\n",
        "def loss(model, x, y, wd):\n",
        "    kernel_variables = []\n",
        "    for l in model.layers:\n",
        "        for w in l.weights:\n",
        "            if 'kernel' in w.name:\n",
        "                kernel_variables.append(w)\n",
        "    wd_penalty = wd * tf.reduce_sum([tf.reduce_sum(tf.square(k)) for k in kernel_variables])\n",
        "    y_ = model(x)\n",
        "    return loss_object(y_true=y, y_pred=y_) + wd_penalty\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)"
      ],
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iJSeMwsYg8Wh"
      },
      "source": [
        "#### Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AwrqhZ_mg8Wi"
      },
      "source": [
        "# Define a function to compute the forward and backward pass\n",
        "\n",
        "def grad(model, inputs, targets, wd):\n",
        "    with tf.GradientTape() as tape:\n",
        "        loss_value = loss(model, inputs, targets, wd)\n",
        "    return loss_value, tape.gradient(loss_value, model.trainable_variables)"
      ],
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UvsyZHwDg8Wj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        },
        "outputId": "bea4d5b0-c896-4785-b3b0-98fc5e8bfa01"
      },
      "source": [
        "# Implement the training loop\n",
        "\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "train_dataset = tf.data.Dataset.from_tensors((x_train, train_labels))\n",
        "train_dataset = train_dataset.batch(32)\n",
        "\n",
        "train_loss_results = []\n",
        "train_accuracy_results = []\n",
        "\n",
        "n_epochs = 10\n",
        "weight_decay = 0.005\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "  epoch_loss_avg = tf.keras.metrics.Mean()\n",
        "  epoch_accuracy = tf.keras.metrics.CategoricalAccuracy()\n",
        "\n",
        "  for x, y in train_dataset:\n",
        "    loss_value, grads = grad(model, x, y, weight_decay)\n",
        "    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
        "\n",
        "    epoch_loss_avg(loss_value)\n",
        "    epoch_accuracy(to_categorical(y), model(x))\n",
        "\n",
        "  train_loss_results.append(epoch_loss_avg.result())\n",
        "  train_accuracy_results.append(epoch_accuracy.result())\n",
        "\n",
        "  print(\"Epoch {:03d}: Loss {:.3f}: Accuracy {:.3%}\".format(\n",
        "      epoch,\n",
        "      epoch_loss_avg.result(),\n",
        "      epoch_accuracy.result()\n",
        "  ))\n",
        "    \n",
        "print(\"Duration :{:.3f}\".format(time.time() - start_time))"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-95-ccc70bc9a469>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mloss_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_decay\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-94-2b7db94d689b>\u001b[0m in \u001b[0;36mgrad\u001b[0;34m(model, inputs, targets, wd)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mloss_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mloss_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-93-8627af2b2268>\u001b[0m in \u001b[0;36mloss\u001b[0;34m(model, x, y, wd)\u001b[0m\n\u001b[1;32m     10\u001b[0m                 \u001b[0mkernel_variables\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mwd_penalty\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwd\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msquare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkernel_variables\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0my_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mloss_object\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mwd_penalty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1010\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1011\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1012\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1013\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-86-9e2876fb035d>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer_1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout_1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1006\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1007\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1008\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1009\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1010\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_maybe_build\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2708\u001b[0m         \u001b[0;31m# operations.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2709\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaybe_init_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2710\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint:disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2711\u001b[0m       \u001b[0;31m# We must set also ensure that the layer is marked as built, and the build\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2712\u001b[0m       \u001b[0;31m# shape is stored since user defined build functions may not be calling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-86-9e2876fb035d>\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     self.w = self.add_weight(\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0minitializer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'random_Normal'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'kernel'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'input_dim' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oLdePp3jg8Wj"
      },
      "source": [
        "#### Evaluate the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AiCghNmEg8Wk"
      },
      "source": [
        "# Create a Dataset object for the test set\n",
        "\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((x_test, test_labels))\n",
        "test_dataset = test_dataset.batch(32)"
      ],
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q9NOk435g8Wk"
      },
      "source": [
        "# Collect average loss and accuracy\n",
        "\n",
        "epoch_loss_avg = tf.keras.metrics.Mean()\n",
        "epoch_accuracy = tf.keras.metrics.CategoricalAccuracy()"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KtBVdJCvg8Wk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "outputId": "d171d0ea-3d2f-416f-885d-d7351015884f"
      },
      "source": [
        "# Loop over the test set and print scores\n",
        "\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "for x, y in test_dataset:\n",
        "    # Optimize the model\n",
        "    loss_value = loss(model, x, y, weight_decay)    \n",
        "    # Compute current loss\n",
        "    epoch_loss_avg(loss_value)  \n",
        "    # Compare predicted label to actual label\n",
        "    epoch_accuracy(to_categorical(y), model(x))\n",
        "\n",
        "print(\"Test loss: {:.3f}\".format(epoch_loss_avg.result().numpy()))\n",
        "print(\"Test accuracy: {:.3%}\".format(epoch_accuracy.result().numpy()))"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-85-52baa918b9ff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_dataset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m# Optimize the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mloss_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_decay\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0;31m# Compute current loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mepoch_loss_avg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'weight_decay' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nykL0bnsg8Wl"
      },
      "source": [
        "#### Plot the learning curves"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "33hnfnLbg8Wl"
      },
      "source": [
        "# Plot the training loss and accuracy\n",
        "\n",
        "fig, axes = plt.subplots(2, sharex=True, figsize=(12, 8))\n",
        "fig.suptitle('Training Metrics')\n",
        "\n",
        "axes[0].set_ylabel(\"Loss\", fontsize=14)\n",
        "axes[0].plot(train_loss_results)\n",
        "\n",
        "axes[1].set_ylabel(\"Accuracy\", fontsize=14)\n",
        "axes[1].set_xlabel(\"Epoch\", fontsize=14)\n",
        "axes[1].plot(train_accuracy_results)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WLrEfECWg8Wm"
      },
      "source": [
        "#### Predict from the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cXBxPfG3g8Wn"
      },
      "source": [
        "# Get the model prediction for an example input\n",
        "\n",
        "predicted_label = np.argmax(model(x_train[np.newaxis,0]),axis=1)[0]\n",
        "print(\"Prediction: {}\".format(class_names[predicted_label]))\n",
        "print(\"     Label: {}\".format(class_names[train_labels[0]]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uLq6de__g8Wo"
      },
      "source": [
        "***\n",
        "<a id=\"coding_tutorial_5\"></a>\n",
        "## tf.function decorator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W7kqfYayg8Wo"
      },
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Layer, Softmax\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.datasets import reuters\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aXu7aDYg8Wp"
      },
      "source": [
        "#### Build the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ylv4Om6tg8Wp"
      },
      "source": [
        "# Initialize a new model\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IWq6cz0Vg8Wq"
      },
      "source": [
        "#### Redefine the grad function using the @tf.function decorator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rejl733Rg8Wq"
      },
      "source": [
        "# Use the @tf.function decorator\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WfkcKGoCg8Wq"
      },
      "source": [
        "#### Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RbLd7QZug8Wr"
      },
      "source": [
        "# Re-run the training loop\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oq178tw-g8Ws"
      },
      "source": [
        "#### Print the autograph code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HN2p_sEEg8Ws"
      },
      "source": [
        "# Use tf.autograph.to_code to see the generated code\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}