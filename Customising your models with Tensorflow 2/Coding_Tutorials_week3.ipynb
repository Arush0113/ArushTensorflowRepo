{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "colab": {
      "name": "Coding Tutorial.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "9b3PNw3gJDI7",
        "hcPUtmz-JDKZ",
        "Zo5rD5ZcJDK_",
        "NrE0rpCVJDL1",
        "yrX43gwPJDL-",
        "MHcNqGnWJDMH",
        "9Ti4kMquJDML",
        "jR7y1e-xJDMd",
        "H3srEhqCJDM7"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Arush0113/ArushTensorflowRepo/blob/main/Customising%20your%20models%20with%20Tensorflow%202/Coding_Tutorials_week3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dk88Aw4NJDIy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a35551b5-6459-4f1d-91df-f420622fc25a"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "\n",
        "print('GPU name: {}'.format(tf.test.gpu_device_name()))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.4.1\n",
            "GPU name: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qQb8nVqLJDI5"
      },
      "source": [
        "# Sequence modelling \n",
        "\n",
        "## Coding tutorials\n",
        " #### 1.  The IMDb dataset\n",
        " #### 2. Padding and masking sequence data\n",
        " #### 3. The `Embedding` layer\n",
        " #### 4. The Embedding Projector\n",
        " #### 5. Recurrent neural network layers\n",
        " #### 6. Stacked RNNs and the `Bidirectional` wrapper"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9b3PNw3gJDI7"
      },
      "source": [
        "***\n",
        "<a id=\"coding_tutorial_1\"></a>\n",
        "## The IMDb Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZwqGZQ8WJDJF"
      },
      "source": [
        "#### Load the IMDB review sentiment dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g3_c1LL5JDJG"
      },
      "source": [
        "# Import imdb\n",
        "\n",
        "import tensorflow.keras.datasets.imdb as imdb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_9jYJCwXJDJK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "525f9a37-a448-4f98-e96f-7f07a12f18c2"
      },
      "source": [
        "# Download and assign the data set using load_data()\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17465344/17464789 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/imdb.py:159: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/imdb.py:160: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0oCnB8UMJDJP"
      },
      "source": [
        "#### Inspect the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "39RwIt-pJDJQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b9c0fd6-80ac-4070-bc14-6f81227c0f62"
      },
      "source": [
        "# Inspect the type of the data\n",
        "\n",
        "print(type(x_train))\n",
        "print(type(y_train))\n",
        "print(type(x_test))\n",
        "print(type(y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Viryy_PDJDJU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2338807-a517-41e3-df12-56cb4ae92f58"
      },
      "source": [
        "# Inspect the shape of the data\n",
        "\n",
        "print(x_train.shape)\n",
        "print(y_train.shape)\n",
        "print(x_test.shape)\n",
        "print(y_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(25000,)\n",
            "(25000,)\n",
            "(25000,)\n",
            "(25000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5q6E6v-FJDJX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89e4cb06-b2ad-44f6-fa9f-2737185a5467"
      },
      "source": [
        "# Display the first dataset element input\n",
        "# Notice encoding\n",
        "\n",
        "x_train[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1,\n",
              " 14,\n",
              " 22,\n",
              " 16,\n",
              " 43,\n",
              " 530,\n",
              " 973,\n",
              " 1622,\n",
              " 1385,\n",
              " 65,\n",
              " 458,\n",
              " 4468,\n",
              " 66,\n",
              " 3941,\n",
              " 4,\n",
              " 173,\n",
              " 36,\n",
              " 256,\n",
              " 5,\n",
              " 25,\n",
              " 100,\n",
              " 43,\n",
              " 838,\n",
              " 112,\n",
              " 50,\n",
              " 670,\n",
              " 22665,\n",
              " 9,\n",
              " 35,\n",
              " 480,\n",
              " 284,\n",
              " 5,\n",
              " 150,\n",
              " 4,\n",
              " 172,\n",
              " 112,\n",
              " 167,\n",
              " 21631,\n",
              " 336,\n",
              " 385,\n",
              " 39,\n",
              " 4,\n",
              " 172,\n",
              " 4536,\n",
              " 1111,\n",
              " 17,\n",
              " 546,\n",
              " 38,\n",
              " 13,\n",
              " 447,\n",
              " 4,\n",
              " 192,\n",
              " 50,\n",
              " 16,\n",
              " 6,\n",
              " 147,\n",
              " 2025,\n",
              " 19,\n",
              " 14,\n",
              " 22,\n",
              " 4,\n",
              " 1920,\n",
              " 4613,\n",
              " 469,\n",
              " 4,\n",
              " 22,\n",
              " 71,\n",
              " 87,\n",
              " 12,\n",
              " 16,\n",
              " 43,\n",
              " 530,\n",
              " 38,\n",
              " 76,\n",
              " 15,\n",
              " 13,\n",
              " 1247,\n",
              " 4,\n",
              " 22,\n",
              " 17,\n",
              " 515,\n",
              " 17,\n",
              " 12,\n",
              " 16,\n",
              " 626,\n",
              " 18,\n",
              " 19193,\n",
              " 5,\n",
              " 62,\n",
              " 386,\n",
              " 12,\n",
              " 8,\n",
              " 316,\n",
              " 8,\n",
              " 106,\n",
              " 5,\n",
              " 4,\n",
              " 2223,\n",
              " 5244,\n",
              " 16,\n",
              " 480,\n",
              " 66,\n",
              " 3785,\n",
              " 33,\n",
              " 4,\n",
              " 130,\n",
              " 12,\n",
              " 16,\n",
              " 38,\n",
              " 619,\n",
              " 5,\n",
              " 25,\n",
              " 124,\n",
              " 51,\n",
              " 36,\n",
              " 135,\n",
              " 48,\n",
              " 25,\n",
              " 1415,\n",
              " 33,\n",
              " 6,\n",
              " 22,\n",
              " 12,\n",
              " 215,\n",
              " 28,\n",
              " 77,\n",
              " 52,\n",
              " 5,\n",
              " 14,\n",
              " 407,\n",
              " 16,\n",
              " 82,\n",
              " 10311,\n",
              " 8,\n",
              " 4,\n",
              " 107,\n",
              " 117,\n",
              " 5952,\n",
              " 15,\n",
              " 256,\n",
              " 4,\n",
              " 31050,\n",
              " 7,\n",
              " 3766,\n",
              " 5,\n",
              " 723,\n",
              " 36,\n",
              " 71,\n",
              " 43,\n",
              " 530,\n",
              " 476,\n",
              " 26,\n",
              " 400,\n",
              " 317,\n",
              " 46,\n",
              " 7,\n",
              " 4,\n",
              " 12118,\n",
              " 1029,\n",
              " 13,\n",
              " 104,\n",
              " 88,\n",
              " 4,\n",
              " 381,\n",
              " 15,\n",
              " 297,\n",
              " 98,\n",
              " 32,\n",
              " 2071,\n",
              " 56,\n",
              " 26,\n",
              " 141,\n",
              " 6,\n",
              " 194,\n",
              " 7486,\n",
              " 18,\n",
              " 4,\n",
              " 226,\n",
              " 22,\n",
              " 21,\n",
              " 134,\n",
              " 476,\n",
              " 26,\n",
              " 480,\n",
              " 5,\n",
              " 144,\n",
              " 30,\n",
              " 5535,\n",
              " 18,\n",
              " 51,\n",
              " 36,\n",
              " 28,\n",
              " 224,\n",
              " 92,\n",
              " 25,\n",
              " 104,\n",
              " 4,\n",
              " 226,\n",
              " 65,\n",
              " 16,\n",
              " 38,\n",
              " 1334,\n",
              " 88,\n",
              " 12,\n",
              " 16,\n",
              " 283,\n",
              " 5,\n",
              " 16,\n",
              " 4472,\n",
              " 113,\n",
              " 103,\n",
              " 32,\n",
              " 15,\n",
              " 16,\n",
              " 5345,\n",
              " 19,\n",
              " 178,\n",
              " 32]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_lbEqyjxJDJc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e80d350b-41ef-4ac1-9655-7eaf2d544106"
      },
      "source": [
        "# Display the first dataset element output\n",
        "\n",
        "y_train[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZAk-PyOgJDJg"
      },
      "source": [
        "#### Load dataset with different options"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mfzFxDj-JDJh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "899c6208-aeda-4d80-835d-2ffb16105f13"
      },
      "source": [
        "# Load the dataset with defaults\n",
        "\n",
        "imdb.load_data(path = 'imdb.npz', index_from = 3)\n",
        "# ~/.keras/dataset/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/imdb.py:159: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/imdb.py:160: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((array([list([1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 22665, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 21631, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 19193, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 10311, 8, 4, 107, 117, 5952, 15, 256, 4, 31050, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 12118, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]),\n",
              "         list([1, 194, 1153, 194, 8255, 78, 228, 5, 6, 1463, 4369, 5012, 134, 26, 4, 715, 8, 118, 1634, 14, 394, 20, 13, 119, 954, 189, 102, 5, 207, 110, 3103, 21, 14, 69, 188, 8, 30, 23, 7, 4, 249, 126, 93, 4, 114, 9, 2300, 1523, 5, 647, 4, 116, 9, 35, 8163, 4, 229, 9, 340, 1322, 4, 118, 9, 4, 130, 4901, 19, 4, 1002, 5, 89, 29, 952, 46, 37, 4, 455, 9, 45, 43, 38, 1543, 1905, 398, 4, 1649, 26, 6853, 5, 163, 11, 3215, 10156, 4, 1153, 9, 194, 775, 7, 8255, 11596, 349, 2637, 148, 605, 15358, 8003, 15, 123, 125, 68, 23141, 6853, 15, 349, 165, 4362, 98, 5, 4, 228, 9, 43, 36893, 1157, 15, 299, 120, 5, 120, 174, 11, 220, 175, 136, 50, 9, 4373, 228, 8255, 5, 25249, 656, 245, 2350, 5, 4, 9837, 131, 152, 491, 18, 46151, 32, 7464, 1212, 14, 9, 6, 371, 78, 22, 625, 64, 1382, 9, 8, 168, 145, 23, 4, 1690, 15, 16, 4, 1355, 5, 28, 6, 52, 154, 462, 33, 89, 78, 285, 16, 145, 95]),\n",
              "         list([1, 14, 47, 8, 30, 31, 7, 4, 249, 108, 7, 4, 5974, 54, 61, 369, 13, 71, 149, 14, 22, 112, 4, 2401, 311, 12, 16, 3711, 33, 75, 43, 1829, 296, 4, 86, 320, 35, 534, 19, 263, 4821, 1301, 4, 1873, 33, 89, 78, 12, 66, 16, 4, 360, 7, 4, 58, 316, 334, 11, 4, 1716, 43, 645, 662, 8, 257, 85, 1200, 42, 1228, 2578, 83, 68, 3912, 15, 36, 165, 1539, 278, 36, 69, 44076, 780, 8, 106, 14, 6905, 1338, 18, 6, 22, 12, 215, 28, 610, 40, 6, 87, 326, 23, 2300, 21, 23, 22, 12, 272, 40, 57, 31, 11, 4, 22, 47, 6, 2307, 51, 9, 170, 23, 595, 116, 595, 1352, 13, 191, 79, 638, 89, 51428, 14, 9, 8, 106, 607, 624, 35, 534, 6, 227, 7, 129, 113]),\n",
              "         ...,\n",
              "         list([1, 11, 6, 230, 245, 6401, 9, 6, 1225, 446, 86527, 45, 2174, 84, 8322, 4007, 21, 4, 912, 84, 14532, 325, 725, 134, 15271, 1715, 84, 5, 36, 28, 57, 1099, 21, 8, 140, 8, 703, 5, 11656, 84, 56, 18, 1644, 14, 9, 31, 7, 4, 9406, 1209, 2295, 26094, 1008, 18, 6, 20, 207, 110, 563, 12, 8, 2901, 17793, 8, 97, 6, 20, 53, 4767, 74, 4, 460, 364, 1273, 29, 270, 11, 960, 108, 45, 40, 29, 2961, 395, 11, 6, 4065, 500, 7, 14492, 89, 364, 70, 29, 140, 4, 64, 4780, 11, 4, 2678, 26, 178, 4, 529, 443, 17793, 5, 27, 710, 117, 74936, 8123, 165, 47, 84, 37, 131, 818, 14, 595, 10, 10, 61, 1242, 1209, 10, 10, 288, 2260, 1702, 34, 2901, 17793, 4, 65, 496, 4, 231, 7, 790, 5, 6, 320, 234, 2766, 234, 1119, 1574, 7, 496, 4, 139, 929, 2901, 17793, 7750, 5, 4241, 18, 4, 8497, 13164, 250, 11, 1818, 7561, 4, 4217, 5408, 747, 1115, 372, 1890, 1006, 541, 9303, 7, 4, 59, 11027, 4, 3586, 22459]),\n",
              "         list([1, 1446, 7079, 69, 72, 3305, 13, 610, 930, 8, 12, 582, 23, 5, 16, 484, 685, 54, 349, 11, 4120, 2959, 45, 58, 1466, 13, 197, 12, 16, 43, 23, 21469, 5, 62, 30, 145, 402, 11, 4131, 51, 575, 32, 61, 369, 71, 66, 770, 12, 1054, 75, 100, 2198, 8, 4, 105, 37, 69, 147, 712, 75, 3543, 44, 257, 390, 5, 69, 263, 514, 105, 50, 286, 1814, 23, 4, 123, 13, 161, 40, 5, 421, 4, 116, 16, 897, 13, 40691, 40, 319, 5872, 112, 6700, 11, 4803, 121, 25, 70, 3468, 4, 719, 3798, 13, 18, 31, 62, 40, 8, 7200, 4, 29455, 7, 14, 123, 5, 942, 25, 8, 721, 12, 145, 5, 202, 12, 160, 580, 202, 12, 6, 52, 58, 11418, 92, 401, 728, 12, 39, 14, 251, 8, 15, 251, 5, 21213, 12, 38, 84, 80, 124, 12, 9, 23]),\n",
              "         list([1, 17, 6, 194, 337, 7, 4, 204, 22, 45, 254, 8, 106, 14, 123, 4, 12815, 270, 14437, 5, 16923, 12255, 732, 2098, 101, 405, 39, 14, 1034, 4, 1310, 9, 115, 50, 305, 12, 47, 4, 168, 5, 235, 7, 38, 111, 699, 102, 7, 4, 4039, 9245, 9, 24, 6, 78, 1099, 17, 2345, 16553, 21, 27, 9685, 6139, 5, 29043, 1603, 92, 1183, 4, 1310, 7, 4, 204, 42, 97, 90, 35, 221, 109, 29, 127, 27, 118, 8, 97, 12, 157, 21, 6789, 85010, 9, 6, 66, 78, 1099, 4, 631, 1191, 5, 2642, 272, 191, 1070, 6, 7585, 8, 2197, 70907, 10755, 544, 5, 383, 1271, 848, 1468, 12183, 497, 16876, 8, 1597, 8778, 19280, 21, 60, 27, 239, 9, 43, 8368, 209, 405, 10, 10, 12, 764, 40, 4, 248, 20, 12, 16, 5, 174, 1791, 72, 7, 51, 6, 1739, 22, 4, 204, 131, 9])],\n",
              "        dtype=object), array([1, 0, 0, ..., 0, 1, 0])),\n",
              " (array([list([1, 591, 202, 14, 31, 6, 717, 10, 10, 18142, 10698, 5, 4, 360, 7, 4, 177, 5760, 394, 354, 4, 123, 9, 1035, 1035, 1035, 10, 10, 13, 92, 124, 89, 488, 7944, 100, 28, 1668, 14, 31, 23, 27, 7479, 29, 220, 468, 8, 124, 14, 286, 170, 8, 157, 46, 5, 27, 239, 16, 179, 15387, 38, 32, 25, 7944, 451, 202, 14, 6, 717]),\n",
              "         list([1, 14, 22, 3443, 6, 176, 7, 5063, 88, 12, 2679, 23, 1310, 5, 109, 943, 4, 114, 9, 55, 606, 5, 111, 7, 4, 139, 193, 273, 23, 4, 172, 270, 11, 7216, 10626, 4, 8463, 2801, 109, 1603, 21, 4, 22, 3861, 8, 6, 1193, 1330, 10, 10, 4, 105, 987, 35, 841, 16873, 19, 861, 1074, 5, 1987, 17975, 45, 55, 221, 15, 670, 5304, 526, 14, 1069, 4, 405, 5, 2438, 7, 27, 85, 108, 131, 4, 5045, 5304, 3884, 405, 9, 3523, 133, 5, 50, 13, 104, 51, 66, 166, 14, 22, 157, 9, 4, 530, 239, 34, 8463, 2801, 45, 407, 31, 7, 41, 3778, 105, 21, 59, 299, 12, 38, 950, 5, 4521, 15, 45, 629, 488, 2733, 127, 6, 52, 292, 17, 4, 6936, 185, 132, 1988, 5304, 1799, 488, 2693, 47, 6, 392, 173, 4, 21686, 4378, 270, 2352, 4, 1500, 7, 4, 65, 55, 73, 11, 346, 14, 20, 9, 6, 976, 2078, 7, 5293, 861, 12746, 5, 4182, 30, 3127, 23651, 56, 4, 841, 5, 990, 692, 8, 4, 1669, 398, 229, 10, 10, 13, 2822, 670, 5304, 14, 9, 31, 7, 27, 111, 108, 15, 2033, 19, 7836, 1429, 875, 551, 14, 22, 9, 1193, 21, 45, 4829, 5, 45, 252, 8, 12508, 6, 565, 921, 3639, 39, 4, 529, 48, 25, 181, 8, 67, 35, 1732, 22, 49, 238, 60, 135, 1162, 14, 9, 290, 4, 58, 10, 10, 472, 45, 55, 878, 8, 169, 11, 374, 5687, 25, 203, 28, 8, 818, 12, 125, 4, 3077]),\n",
              "         list([1, 111, 748, 4368, 1133, 33782, 24563, 4, 87, 1551, 1262, 7, 31, 318, 9459, 7, 4, 498, 5076, 748, 63, 29, 5161, 220, 686, 10941, 5, 17, 12, 575, 220, 2507, 17, 6, 185, 132, 24563, 16, 53, 928, 11, 51278, 74, 4, 438, 21, 27, 10044, 589, 8, 22, 107, 20123, 19550, 997, 1638, 8, 35, 2076, 9019, 11, 22, 231, 54, 29, 1706, 29, 100, 18995, 2425, 34, 12998, 8738, 48078, 5, 19353, 98, 31, 2122, 33, 6, 58, 14, 3808, 1638, 8, 4, 365, 7, 2789, 3761, 356, 346, 4, 27608, 1060, 63, 29, 93, 11, 5421, 11, 15236, 33, 6, 58, 54, 1270, 431, 748, 7, 32, 2580, 16, 11, 94, 19469, 10, 10, 4, 993, 45222, 7, 4, 1766, 2634, 2164, 24563, 8, 847, 8, 1450, 121, 31, 7, 27, 86, 2663, 10760, 16, 6, 465, 993, 2006, 30995, 573, 17, 61862, 42, 4, 17345, 37, 473, 6, 711, 6, 8869, 7, 328, 212, 70, 30, 258, 11, 220, 32, 7, 108, 21, 133, 12, 9, 55, 465, 849, 3711, 53, 33, 2071, 1969, 37, 70, 1144, 4, 5940, 1409, 74, 476, 37, 62, 91, 1329, 169, 4, 1330, 10104, 146, 655, 2212, 5, 258, 12, 184, 10104, 546, 5, 849, 10333, 7, 4, 22, 1436, 18, 631, 1386, 797, 7, 4, 8712, 71, 348, 425, 4320, 1061, 19, 10288, 5, 12141, 11, 661, 8, 339, 17863, 4, 2455, 11434, 7, 4, 1962, 10, 10, 263, 787, 9, 270, 11, 6, 9466, 4, 61862, 48414, 121, 4, 5437, 26, 4434, 19, 68, 1372, 5, 28, 446, 6, 318, 7149, 8, 67, 51, 36, 70, 81, 8, 4392, 2294, 36, 1197, 8, 68411, 25399, 18, 6, 711, 4, 9909, 26, 10296, 1125, 11, 14, 636, 720, 12, 426, 28, 77, 776, 8, 97, 38, 111, 7489, 6175, 168, 1239, 5189, 137, 25399, 18, 27, 173, 9, 2399, 17, 6, 12397, 428, 14657, 232, 11, 4, 8014, 37, 272, 40, 2708, 247, 30, 656, 6, 13182, 54, 25399, 3292, 98, 6, 2840, 40, 558, 37, 6093, 98, 4, 17345, 1197, 15, 14, 9, 57, 4893, 5, 4659, 6, 275, 711, 7937, 25399, 3292, 98, 6, 31036, 10, 10, 6639, 19, 14, 10241, 267, 162, 711, 37, 5900, 752, 98, 4, 17345, 2378, 90, 19, 6, 73284, 7, 36744, 1810, 77553, 4, 4770, 3183, 930, 8, 508, 90, 4, 1317, 8, 4, 48414, 17, 15454, 3965, 1853, 4, 1494, 8, 4468, 189, 4, 31036, 6287, 5774, 4, 4770, 5, 95, 271, 23, 6, 7742, 6063, 21627, 5437, 33, 1526, 6, 425, 3155, 33697, 4535, 1636, 7, 4, 4669, 11966, 469, 4, 4552, 54, 4, 150, 5664, 17345, 280, 53, 68411, 25399, 18, 339, 29, 1978, 27, 7885, 5, 17303, 68, 1830, 19, 6571, 14605, 4, 1515, 7, 263, 65, 2132, 34, 6, 5680, 7489, 43, 159, 29, 9, 4706, 9, 387, 73, 195, 584, 10, 10, 1069, 4, 58, 810, 54, 14, 6078, 117, 22, 16, 93, 5, 1069, 4, 192, 15, 12, 16, 93, 34, 6, 1766, 28228, 33, 4, 5673, 7, 15, 18760, 9252, 3286, 325, 12, 62, 30, 776, 8, 67, 14, 17, 6, 12214, 44, 148, 687, 24563, 203, 42, 203, 24, 28, 69, 32157, 6676, 11, 330, 54, 29, 93, 61862, 21, 845, 14148, 27, 1099, 7, 819, 4, 22, 1407, 17, 6, 14967, 787, 7, 2460, 19569, 61862, 100, 30, 4, 3737, 3617, 3169, 2321, 42, 1898, 11, 4, 3814, 42, 101, 704, 7, 101, 999, 15, 1625, 94, 2926, 180, 5, 9, 9101, 34, 15205, 45, 6, 1429, 22, 60, 6, 1220, 31, 11, 94, 6408, 96, 21, 94, 749, 9, 57, 975]),\n",
              "         ...,\n",
              "         list([1, 13, 1408, 15, 8, 135, 14, 9, 35, 32, 46, 394, 20, 62, 30, 5093, 21, 45, 184, 78, 4, 1492, 910, 769, 2290, 2515, 395, 4257, 5, 1454, 11, 119, 16946, 89, 1036, 4, 116, 218, 78, 21, 407, 100, 30, 128, 262, 15, 7, 185, 2280, 284, 1842, 60664, 37, 315, 4, 226, 20, 272, 2942, 40, 29, 152, 60, 181, 8, 30, 50, 553, 362, 80, 119, 12, 21, 846, 5518]),\n",
              "         list([1, 11, 119, 241, 9, 4, 840, 20, 12, 468, 15, 94, 3684, 562, 791, 39, 4, 86, 107, 8, 97, 14, 31, 33, 4, 2960, 7, 743, 46, 1028, 9, 3531, 5, 4, 768, 47, 8, 79, 90, 145, 164, 162, 50, 6, 501, 119, 7, 9, 4, 78, 232, 15, 16, 224, 11, 4, 333, 20, 4, 985, 200, 5, 28739, 5, 9, 1861, 8, 79, 357, 4, 20, 47, 220, 57, 206, 139, 11, 12, 5, 55, 117, 212, 13, 1276, 92, 124, 51, 45, 1188, 71, 536, 13, 520, 14, 20, 6, 2302, 7, 470]),\n",
              "         list([1, 6, 52, 7465, 430, 22, 9, 220, 2594, 8, 28, 24357, 519, 3227, 6, 769, 15, 47, 6, 3482, 4067, 8, 114, 5, 33, 222, 31, 55, 184, 704, 5586, 18020, 19, 346, 3153, 5, 6, 364, 350, 4, 184, 5586, 9, 133, 1810, 11, 5417, 13226, 21, 4, 7298, 42657, 570, 50, 2005, 2643, 9, 6, 1249, 17, 6, 25194, 27803, 21, 17, 6, 1211, 232, 1138, 2249, 29, 266, 56, 96, 346, 194, 308, 9, 194, 21, 29, 218, 1078, 19, 4, 78, 173, 7, 27, 20067, 5698, 3406, 718, 21264, 9, 6, 6907, 17, 210, 5, 3281, 5677, 47, 77, 395, 14, 172, 173, 18, 2740, 2931, 4517, 82, 127, 27, 173, 11, 6, 392, 217, 21, 50, 9, 57, 65, 12, 14274, 53, 40, 35, 390, 7, 11, 4, 3567, 7, 4, 314, 74, 6, 792, 22, 16261, 19, 714, 727, 5205, 382, 4, 91, 6533, 439, 19, 14, 20, 9, 1441, 5805, 1118, 4, 756, 25, 124, 4, 31, 12, 16, 93, 804, 34, 2005, 2643])],\n",
              "        dtype=object),\n",
              "  array([0, 1, 1, ..., 0, 0, 0])))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kuGfzZg3JDJv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c07d323-37cd-44b5-a380-290187537ef2"
      },
      "source": [
        "# Limit the vocabulary to the top 500 words using num_words\n",
        "\n",
        "imdb.load_data(num_words=500)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/imdb.py:159: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/imdb.py:160: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((array([list([1, 14, 22, 16, 43, 2, 2, 2, 2, 65, 458, 2, 66, 2, 4, 173, 36, 256, 5, 25, 100, 43, 2, 112, 50, 2, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 2, 2, 17, 2, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2, 19, 14, 22, 4, 2, 2, 469, 4, 22, 71, 87, 12, 16, 43, 2, 38, 76, 15, 13, 2, 4, 22, 17, 2, 17, 12, 16, 2, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2, 2, 16, 480, 66, 2, 33, 4, 130, 12, 16, 38, 2, 5, 25, 124, 51, 36, 135, 48, 25, 2, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 2, 15, 256, 4, 2, 7, 2, 5, 2, 36, 71, 43, 2, 476, 26, 400, 317, 46, 7, 4, 2, 2, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2, 56, 26, 141, 6, 194, 2, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 2, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 2, 88, 12, 16, 283, 5, 16, 2, 113, 103, 32, 15, 16, 2, 19, 178, 32]),\n",
              "         list([1, 194, 2, 194, 2, 78, 228, 5, 6, 2, 2, 2, 134, 26, 4, 2, 8, 118, 2, 14, 394, 20, 13, 119, 2, 189, 102, 5, 207, 110, 2, 21, 14, 69, 188, 8, 30, 23, 7, 4, 249, 126, 93, 4, 114, 9, 2, 2, 5, 2, 4, 116, 9, 35, 2, 4, 229, 9, 340, 2, 4, 118, 9, 4, 130, 2, 19, 4, 2, 5, 89, 29, 2, 46, 37, 4, 455, 9, 45, 43, 38, 2, 2, 398, 4, 2, 26, 2, 5, 163, 11, 2, 2, 4, 2, 9, 194, 2, 7, 2, 2, 349, 2, 148, 2, 2, 2, 15, 123, 125, 68, 2, 2, 15, 349, 165, 2, 98, 5, 4, 228, 9, 43, 2, 2, 15, 299, 120, 5, 120, 174, 11, 220, 175, 136, 50, 9, 2, 228, 2, 5, 2, 2, 245, 2, 5, 4, 2, 131, 152, 491, 18, 2, 32, 2, 2, 14, 9, 6, 371, 78, 22, 2, 64, 2, 9, 8, 168, 145, 23, 4, 2, 15, 16, 4, 2, 5, 28, 6, 52, 154, 462, 33, 89, 78, 285, 16, 145, 95]),\n",
              "         list([1, 14, 47, 8, 30, 31, 7, 4, 249, 108, 7, 4, 2, 54, 61, 369, 13, 71, 149, 14, 22, 112, 4, 2, 311, 12, 16, 2, 33, 75, 43, 2, 296, 4, 86, 320, 35, 2, 19, 263, 2, 2, 4, 2, 33, 89, 78, 12, 66, 16, 4, 360, 7, 4, 58, 316, 334, 11, 4, 2, 43, 2, 2, 8, 257, 85, 2, 42, 2, 2, 83, 68, 2, 15, 36, 165, 2, 278, 36, 69, 2, 2, 8, 106, 14, 2, 2, 18, 6, 22, 12, 215, 28, 2, 40, 6, 87, 326, 23, 2, 21, 23, 22, 12, 272, 40, 57, 31, 11, 4, 22, 47, 6, 2, 51, 9, 170, 23, 2, 116, 2, 2, 13, 191, 79, 2, 89, 2, 14, 9, 8, 106, 2, 2, 35, 2, 6, 227, 7, 129, 113]),\n",
              "         ...,\n",
              "         list([1, 11, 6, 230, 245, 2, 9, 6, 2, 446, 2, 45, 2, 84, 2, 2, 21, 4, 2, 84, 2, 325, 2, 134, 2, 2, 84, 5, 36, 28, 57, 2, 21, 8, 140, 8, 2, 5, 2, 84, 56, 18, 2, 14, 9, 31, 7, 4, 2, 2, 2, 2, 2, 18, 6, 20, 207, 110, 2, 12, 8, 2, 2, 8, 97, 6, 20, 53, 2, 74, 4, 460, 364, 2, 29, 270, 11, 2, 108, 45, 40, 29, 2, 395, 11, 6, 2, 2, 7, 2, 89, 364, 70, 29, 140, 4, 64, 2, 11, 4, 2, 26, 178, 4, 2, 443, 2, 5, 27, 2, 117, 2, 2, 165, 47, 84, 37, 131, 2, 14, 2, 10, 10, 61, 2, 2, 10, 10, 288, 2, 2, 34, 2, 2, 4, 65, 496, 4, 231, 7, 2, 5, 6, 320, 234, 2, 234, 2, 2, 7, 496, 4, 139, 2, 2, 2, 2, 5, 2, 18, 4, 2, 2, 250, 11, 2, 2, 4, 2, 2, 2, 2, 372, 2, 2, 2, 2, 7, 4, 59, 2, 4, 2, 2]),\n",
              "         list([1, 2, 2, 69, 72, 2, 13, 2, 2, 8, 12, 2, 23, 5, 16, 484, 2, 54, 349, 11, 2, 2, 45, 58, 2, 13, 197, 12, 16, 43, 23, 2, 5, 62, 30, 145, 402, 11, 2, 51, 2, 32, 61, 369, 71, 66, 2, 12, 2, 75, 100, 2, 8, 4, 105, 37, 69, 147, 2, 75, 2, 44, 257, 390, 5, 69, 263, 2, 105, 50, 286, 2, 23, 4, 123, 13, 161, 40, 5, 421, 4, 116, 16, 2, 13, 2, 40, 319, 2, 112, 2, 11, 2, 121, 25, 70, 2, 4, 2, 2, 13, 18, 31, 62, 40, 8, 2, 4, 2, 7, 14, 123, 5, 2, 25, 8, 2, 12, 145, 5, 202, 12, 160, 2, 202, 12, 6, 52, 58, 2, 92, 401, 2, 12, 39, 14, 251, 8, 15, 251, 5, 2, 12, 38, 84, 80, 124, 12, 9, 23]),\n",
              "         list([1, 17, 6, 194, 337, 7, 4, 204, 22, 45, 254, 8, 106, 14, 123, 4, 2, 270, 2, 5, 2, 2, 2, 2, 101, 405, 39, 14, 2, 4, 2, 9, 115, 50, 305, 12, 47, 4, 168, 5, 235, 7, 38, 111, 2, 102, 7, 4, 2, 2, 9, 24, 6, 78, 2, 17, 2, 2, 21, 27, 2, 2, 5, 2, 2, 92, 2, 4, 2, 7, 4, 204, 42, 97, 90, 35, 221, 109, 29, 127, 27, 118, 8, 97, 12, 157, 21, 2, 2, 9, 6, 66, 78, 2, 4, 2, 2, 5, 2, 272, 191, 2, 6, 2, 8, 2, 2, 2, 2, 5, 383, 2, 2, 2, 2, 497, 2, 8, 2, 2, 2, 21, 60, 27, 239, 9, 43, 2, 209, 405, 10, 10, 12, 2, 40, 4, 248, 20, 12, 16, 5, 174, 2, 72, 7, 51, 6, 2, 22, 4, 204, 131, 9])],\n",
              "        dtype=object), array([1, 0, 0, ..., 0, 1, 0])),\n",
              " (array([list([1, 2, 202, 14, 31, 6, 2, 10, 10, 2, 2, 5, 4, 360, 7, 4, 177, 2, 394, 354, 4, 123, 9, 2, 2, 2, 10, 10, 13, 92, 124, 89, 488, 2, 100, 28, 2, 14, 31, 23, 27, 2, 29, 220, 468, 8, 124, 14, 286, 170, 8, 157, 46, 5, 27, 239, 16, 179, 2, 38, 32, 25, 2, 451, 202, 14, 6, 2]),\n",
              "         list([1, 14, 22, 2, 6, 176, 7, 2, 88, 12, 2, 23, 2, 5, 109, 2, 4, 114, 9, 55, 2, 5, 111, 7, 4, 139, 193, 273, 23, 4, 172, 270, 11, 2, 2, 4, 2, 2, 109, 2, 21, 4, 22, 2, 8, 6, 2, 2, 10, 10, 4, 105, 2, 35, 2, 2, 19, 2, 2, 5, 2, 2, 45, 55, 221, 15, 2, 2, 2, 14, 2, 4, 405, 5, 2, 7, 27, 85, 108, 131, 4, 2, 2, 2, 405, 9, 2, 133, 5, 50, 13, 104, 51, 66, 166, 14, 22, 157, 9, 4, 2, 239, 34, 2, 2, 45, 407, 31, 7, 41, 2, 105, 21, 59, 299, 12, 38, 2, 5, 2, 15, 45, 2, 488, 2, 127, 6, 52, 292, 17, 4, 2, 185, 132, 2, 2, 2, 488, 2, 47, 6, 392, 173, 4, 2, 2, 270, 2, 4, 2, 7, 4, 65, 55, 73, 11, 346, 14, 20, 9, 6, 2, 2, 7, 2, 2, 2, 5, 2, 30, 2, 2, 56, 4, 2, 5, 2, 2, 8, 4, 2, 398, 229, 10, 10, 13, 2, 2, 2, 14, 9, 31, 7, 27, 111, 108, 15, 2, 19, 2, 2, 2, 2, 14, 22, 9, 2, 21, 45, 2, 5, 45, 252, 8, 2, 6, 2, 2, 2, 39, 4, 2, 48, 25, 181, 8, 67, 35, 2, 22, 49, 238, 60, 135, 2, 14, 9, 290, 4, 58, 10, 10, 472, 45, 55, 2, 8, 169, 11, 374, 2, 25, 203, 28, 8, 2, 12, 125, 4, 2]),\n",
              "         list([1, 111, 2, 2, 2, 2, 2, 4, 87, 2, 2, 7, 31, 318, 2, 7, 4, 498, 2, 2, 63, 29, 2, 220, 2, 2, 5, 17, 12, 2, 220, 2, 17, 6, 185, 132, 2, 16, 53, 2, 11, 2, 74, 4, 438, 21, 27, 2, 2, 8, 22, 107, 2, 2, 2, 2, 8, 35, 2, 2, 11, 22, 231, 54, 29, 2, 29, 100, 2, 2, 34, 2, 2, 2, 5, 2, 98, 31, 2, 33, 6, 58, 14, 2, 2, 8, 4, 365, 7, 2, 2, 356, 346, 4, 2, 2, 63, 29, 93, 11, 2, 11, 2, 33, 6, 58, 54, 2, 431, 2, 7, 32, 2, 16, 11, 94, 2, 10, 10, 4, 2, 2, 7, 4, 2, 2, 2, 2, 8, 2, 8, 2, 121, 31, 7, 27, 86, 2, 2, 16, 6, 465, 2, 2, 2, 2, 17, 2, 42, 4, 2, 37, 473, 6, 2, 6, 2, 7, 328, 212, 70, 30, 258, 11, 220, 32, 7, 108, 21, 133, 12, 9, 55, 465, 2, 2, 53, 33, 2, 2, 37, 70, 2, 4, 2, 2, 74, 476, 37, 62, 91, 2, 169, 4, 2, 2, 146, 2, 2, 5, 258, 12, 184, 2, 2, 5, 2, 2, 7, 4, 22, 2, 18, 2, 2, 2, 7, 4, 2, 71, 348, 425, 2, 2, 19, 2, 5, 2, 11, 2, 8, 339, 2, 4, 2, 2, 7, 4, 2, 10, 10, 263, 2, 9, 270, 11, 6, 2, 4, 2, 2, 121, 4, 2, 26, 2, 19, 68, 2, 5, 28, 446, 6, 318, 2, 8, 67, 51, 36, 70, 81, 8, 2, 2, 36, 2, 8, 2, 2, 18, 6, 2, 4, 2, 26, 2, 2, 11, 14, 2, 2, 12, 426, 28, 77, 2, 8, 97, 38, 111, 2, 2, 168, 2, 2, 137, 2, 18, 27, 173, 9, 2, 17, 6, 2, 428, 2, 232, 11, 4, 2, 37, 272, 40, 2, 247, 30, 2, 6, 2, 54, 2, 2, 98, 6, 2, 40, 2, 37, 2, 98, 4, 2, 2, 15, 14, 9, 57, 2, 5, 2, 6, 275, 2, 2, 2, 2, 98, 6, 2, 10, 10, 2, 19, 14, 2, 267, 162, 2, 37, 2, 2, 98, 4, 2, 2, 90, 19, 6, 2, 7, 2, 2, 2, 4, 2, 2, 2, 8, 2, 90, 4, 2, 8, 4, 2, 17, 2, 2, 2, 4, 2, 8, 2, 189, 4, 2, 2, 2, 4, 2, 5, 95, 271, 23, 6, 2, 2, 2, 2, 33, 2, 6, 425, 2, 2, 2, 2, 7, 4, 2, 2, 469, 4, 2, 54, 4, 150, 2, 2, 280, 53, 2, 2, 18, 339, 29, 2, 27, 2, 5, 2, 68, 2, 19, 2, 2, 4, 2, 7, 263, 65, 2, 34, 6, 2, 2, 43, 159, 29, 9, 2, 9, 387, 73, 195, 2, 10, 10, 2, 4, 58, 2, 54, 14, 2, 117, 22, 16, 93, 5, 2, 4, 192, 15, 12, 16, 93, 34, 6, 2, 2, 33, 4, 2, 7, 15, 2, 2, 2, 325, 12, 62, 30, 2, 8, 67, 14, 17, 6, 2, 44, 148, 2, 2, 203, 42, 203, 24, 28, 69, 2, 2, 11, 330, 54, 29, 93, 2, 21, 2, 2, 27, 2, 7, 2, 4, 22, 2, 17, 6, 2, 2, 7, 2, 2, 2, 100, 30, 4, 2, 2, 2, 2, 42, 2, 11, 4, 2, 42, 101, 2, 7, 101, 2, 15, 2, 94, 2, 180, 5, 9, 2, 34, 2, 45, 6, 2, 22, 60, 6, 2, 31, 11, 94, 2, 96, 21, 94, 2, 9, 57, 2]),\n",
              "         ...,\n",
              "         list([1, 13, 2, 15, 8, 135, 14, 9, 35, 32, 46, 394, 20, 62, 30, 2, 21, 45, 184, 78, 4, 2, 2, 2, 2, 2, 395, 2, 5, 2, 11, 119, 2, 89, 2, 4, 116, 218, 78, 21, 407, 100, 30, 128, 262, 15, 7, 185, 2, 284, 2, 2, 37, 315, 4, 226, 20, 272, 2, 40, 29, 152, 60, 181, 8, 30, 50, 2, 362, 80, 119, 12, 21, 2, 2]),\n",
              "         list([1, 11, 119, 241, 9, 4, 2, 20, 12, 468, 15, 94, 2, 2, 2, 39, 4, 86, 107, 8, 97, 14, 31, 33, 4, 2, 7, 2, 46, 2, 9, 2, 5, 4, 2, 47, 8, 79, 90, 145, 164, 162, 50, 6, 2, 119, 7, 9, 4, 78, 232, 15, 16, 224, 11, 4, 333, 20, 4, 2, 200, 5, 2, 5, 9, 2, 8, 79, 357, 4, 20, 47, 220, 57, 206, 139, 11, 12, 5, 55, 117, 212, 13, 2, 92, 124, 51, 45, 2, 71, 2, 13, 2, 14, 20, 6, 2, 7, 470]),\n",
              "         list([1, 6, 52, 2, 430, 22, 9, 220, 2, 8, 28, 2, 2, 2, 6, 2, 15, 47, 6, 2, 2, 8, 114, 5, 33, 222, 31, 55, 184, 2, 2, 2, 19, 346, 2, 5, 6, 364, 350, 4, 184, 2, 9, 133, 2, 11, 2, 2, 21, 4, 2, 2, 2, 50, 2, 2, 9, 6, 2, 17, 6, 2, 2, 21, 17, 6, 2, 232, 2, 2, 29, 266, 56, 96, 346, 194, 308, 9, 194, 21, 29, 218, 2, 19, 4, 78, 173, 7, 27, 2, 2, 2, 2, 2, 9, 6, 2, 17, 210, 5, 2, 2, 47, 77, 395, 14, 172, 173, 18, 2, 2, 2, 82, 127, 27, 173, 11, 6, 392, 217, 21, 50, 9, 57, 65, 12, 2, 53, 40, 35, 390, 7, 11, 4, 2, 7, 4, 314, 74, 6, 2, 22, 2, 19, 2, 2, 2, 382, 4, 91, 2, 439, 19, 14, 20, 9, 2, 2, 2, 4, 2, 25, 124, 4, 31, 12, 16, 93, 2, 34, 2, 2])],\n",
              "        dtype=object),\n",
              "  array([0, 1, 1, ..., 0, 0, 0])))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pMkXgUGaJDJy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31817dba-2844-4d2d-895a-85cb4f3692ac"
      },
      "source": [
        "# Ignore the top 10 most frequent words using skip_top\n",
        "\n",
        "imdb.load_data(skip_top = 10, num_words=1000, oov_char=2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/imdb.py:159: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/imdb.py:160: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((array([list([2, 14, 22, 16, 43, 530, 973, 2, 2, 65, 458, 2, 66, 2, 2, 173, 36, 256, 2, 25, 100, 43, 838, 112, 50, 670, 2, 2, 35, 480, 284, 2, 150, 2, 172, 112, 167, 2, 336, 385, 39, 2, 172, 2, 2, 17, 546, 38, 13, 447, 2, 192, 50, 16, 2, 147, 2, 19, 14, 22, 2, 2, 2, 469, 2, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 2, 2, 22, 17, 515, 17, 12, 16, 626, 18, 2, 2, 62, 386, 12, 2, 316, 2, 106, 2, 2, 2, 2, 16, 480, 66, 2, 33, 2, 130, 12, 16, 38, 619, 2, 25, 124, 51, 36, 135, 48, 25, 2, 33, 2, 22, 12, 215, 28, 77, 52, 2, 14, 407, 16, 82, 2, 2, 2, 107, 117, 2, 15, 256, 2, 2, 2, 2, 2, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 2, 2, 2, 2, 13, 104, 88, 2, 381, 15, 297, 98, 32, 2, 56, 26, 141, 2, 194, 2, 18, 2, 226, 22, 21, 134, 476, 26, 480, 2, 144, 30, 2, 18, 51, 36, 28, 224, 92, 25, 104, 2, 226, 65, 16, 38, 2, 88, 12, 16, 283, 2, 16, 2, 113, 103, 32, 15, 16, 2, 19, 178, 32]),\n",
              "         list([2, 194, 2, 194, 2, 78, 228, 2, 2, 2, 2, 2, 134, 26, 2, 715, 2, 118, 2, 14, 394, 20, 13, 119, 954, 189, 102, 2, 207, 110, 2, 21, 14, 69, 188, 2, 30, 23, 2, 2, 249, 126, 93, 2, 114, 2, 2, 2, 2, 647, 2, 116, 2, 35, 2, 2, 229, 2, 340, 2, 2, 118, 2, 2, 130, 2, 19, 2, 2, 2, 89, 29, 952, 46, 37, 2, 455, 2, 45, 43, 38, 2, 2, 398, 2, 2, 26, 2, 2, 163, 11, 2, 2, 2, 2, 2, 194, 775, 2, 2, 2, 349, 2, 148, 605, 2, 2, 15, 123, 125, 68, 2, 2, 15, 349, 165, 2, 98, 2, 2, 228, 2, 43, 2, 2, 15, 299, 120, 2, 120, 174, 11, 220, 175, 136, 50, 2, 2, 228, 2, 2, 2, 656, 245, 2, 2, 2, 2, 131, 152, 491, 18, 2, 32, 2, 2, 14, 2, 2, 371, 78, 22, 625, 64, 2, 2, 2, 168, 145, 23, 2, 2, 15, 16, 2, 2, 2, 28, 2, 52, 154, 462, 33, 89, 78, 285, 16, 145, 95]),\n",
              "         list([2, 14, 47, 2, 30, 31, 2, 2, 249, 108, 2, 2, 2, 54, 61, 369, 13, 71, 149, 14, 22, 112, 2, 2, 311, 12, 16, 2, 33, 75, 43, 2, 296, 2, 86, 320, 35, 534, 19, 263, 2, 2, 2, 2, 33, 89, 78, 12, 66, 16, 2, 360, 2, 2, 58, 316, 334, 11, 2, 2, 43, 645, 662, 2, 257, 85, 2, 42, 2, 2, 83, 68, 2, 15, 36, 165, 2, 278, 36, 69, 2, 780, 2, 106, 14, 2, 2, 18, 2, 22, 12, 215, 28, 610, 40, 2, 87, 326, 23, 2, 21, 23, 22, 12, 272, 40, 57, 31, 11, 2, 22, 47, 2, 2, 51, 2, 170, 23, 595, 116, 595, 2, 13, 191, 79, 638, 89, 2, 14, 2, 2, 106, 607, 624, 35, 534, 2, 227, 2, 129, 113]),\n",
              "         ...,\n",
              "         list([2, 11, 2, 230, 245, 2, 2, 2, 2, 446, 2, 45, 2, 84, 2, 2, 21, 2, 912, 84, 2, 325, 725, 134, 2, 2, 84, 2, 36, 28, 57, 2, 21, 2, 140, 2, 703, 2, 2, 84, 56, 18, 2, 14, 2, 31, 2, 2, 2, 2, 2, 2, 2, 18, 2, 20, 207, 110, 563, 12, 2, 2, 2, 2, 97, 2, 20, 53, 2, 74, 2, 460, 364, 2, 29, 270, 11, 960, 108, 45, 40, 29, 2, 395, 11, 2, 2, 500, 2, 2, 89, 364, 70, 29, 140, 2, 64, 2, 11, 2, 2, 26, 178, 2, 529, 443, 2, 2, 27, 710, 117, 2, 2, 165, 47, 84, 37, 131, 818, 14, 595, 10, 10, 61, 2, 2, 10, 10, 288, 2, 2, 34, 2, 2, 2, 65, 496, 2, 231, 2, 790, 2, 2, 320, 234, 2, 234, 2, 2, 2, 496, 2, 139, 929, 2, 2, 2, 2, 2, 18, 2, 2, 2, 250, 11, 2, 2, 2, 2, 2, 747, 2, 372, 2, 2, 541, 2, 2, 2, 59, 2, 2, 2, 2]),\n",
              "         list([2, 2, 2, 69, 72, 2, 13, 610, 930, 2, 12, 582, 23, 2, 16, 484, 685, 54, 349, 11, 2, 2, 45, 58, 2, 13, 197, 12, 16, 43, 23, 2, 2, 62, 30, 145, 402, 11, 2, 51, 575, 32, 61, 369, 71, 66, 770, 12, 2, 75, 100, 2, 2, 2, 105, 37, 69, 147, 712, 75, 2, 44, 257, 390, 2, 69, 263, 514, 105, 50, 286, 2, 23, 2, 123, 13, 161, 40, 2, 421, 2, 116, 16, 897, 13, 2, 40, 319, 2, 112, 2, 11, 2, 121, 25, 70, 2, 2, 719, 2, 13, 18, 31, 62, 40, 2, 2, 2, 2, 2, 14, 123, 2, 942, 25, 2, 721, 12, 145, 2, 202, 12, 160, 580, 202, 12, 2, 52, 58, 2, 92, 401, 728, 12, 39, 14, 251, 2, 15, 251, 2, 2, 12, 38, 84, 80, 124, 12, 2, 23]),\n",
              "         list([2, 17, 2, 194, 337, 2, 2, 204, 22, 45, 254, 2, 106, 14, 123, 2, 2, 270, 2, 2, 2, 2, 732, 2, 101, 405, 39, 14, 2, 2, 2, 2, 115, 50, 305, 12, 47, 2, 168, 2, 235, 2, 38, 111, 699, 102, 2, 2, 2, 2, 2, 24, 2, 78, 2, 17, 2, 2, 21, 27, 2, 2, 2, 2, 2, 92, 2, 2, 2, 2, 2, 204, 42, 97, 90, 35, 221, 109, 29, 127, 27, 118, 2, 97, 12, 157, 21, 2, 2, 2, 2, 66, 78, 2, 2, 631, 2, 2, 2, 272, 191, 2, 2, 2, 2, 2, 2, 2, 544, 2, 383, 2, 848, 2, 2, 497, 2, 2, 2, 2, 2, 21, 60, 27, 239, 2, 43, 2, 209, 405, 10, 10, 12, 764, 40, 2, 248, 20, 12, 16, 2, 174, 2, 72, 2, 51, 2, 2, 22, 2, 204, 131, 2])],\n",
              "        dtype=object), array([1, 0, 0, ..., 0, 1, 0])),\n",
              " (array([list([2, 591, 202, 14, 31, 2, 717, 10, 10, 2, 2, 2, 2, 360, 2, 2, 177, 2, 394, 354, 2, 123, 2, 2, 2, 2, 10, 10, 13, 92, 124, 89, 488, 2, 100, 28, 2, 14, 31, 23, 27, 2, 29, 220, 468, 2, 124, 14, 286, 170, 2, 157, 46, 2, 27, 239, 16, 179, 2, 38, 32, 25, 2, 451, 202, 14, 2, 717]),\n",
              "         list([2, 14, 22, 2, 2, 176, 2, 2, 88, 12, 2, 23, 2, 2, 109, 943, 2, 114, 2, 55, 606, 2, 111, 2, 2, 139, 193, 273, 23, 2, 172, 270, 11, 2, 2, 2, 2, 2, 109, 2, 21, 2, 22, 2, 2, 2, 2, 2, 10, 10, 2, 105, 987, 35, 841, 2, 19, 861, 2, 2, 2, 2, 45, 55, 221, 15, 670, 2, 526, 14, 2, 2, 405, 2, 2, 2, 27, 85, 108, 131, 2, 2, 2, 2, 405, 2, 2, 133, 2, 50, 13, 104, 51, 66, 166, 14, 22, 157, 2, 2, 530, 239, 34, 2, 2, 45, 407, 31, 2, 41, 2, 105, 21, 59, 299, 12, 38, 950, 2, 2, 15, 45, 629, 488, 2, 127, 2, 52, 292, 17, 2, 2, 185, 132, 2, 2, 2, 488, 2, 47, 2, 392, 173, 2, 2, 2, 270, 2, 2, 2, 2, 2, 65, 55, 73, 11, 346, 14, 20, 2, 2, 976, 2, 2, 2, 861, 2, 2, 2, 30, 2, 2, 56, 2, 841, 2, 990, 692, 2, 2, 2, 398, 229, 10, 10, 13, 2, 670, 2, 14, 2, 31, 2, 27, 111, 108, 15, 2, 19, 2, 2, 875, 551, 14, 22, 2, 2, 21, 45, 2, 2, 45, 252, 2, 2, 2, 565, 921, 2, 39, 2, 529, 48, 25, 181, 2, 67, 35, 2, 22, 49, 238, 60, 135, 2, 14, 2, 290, 2, 58, 10, 10, 472, 45, 55, 878, 2, 169, 11, 374, 2, 25, 203, 28, 2, 818, 12, 125, 2, 2]),\n",
              "         list([2, 111, 748, 2, 2, 2, 2, 2, 87, 2, 2, 2, 31, 318, 2, 2, 2, 498, 2, 748, 63, 29, 2, 220, 686, 2, 2, 17, 12, 575, 220, 2, 17, 2, 185, 132, 2, 16, 53, 928, 11, 2, 74, 2, 438, 21, 27, 2, 589, 2, 22, 107, 2, 2, 997, 2, 2, 35, 2, 2, 11, 22, 231, 54, 29, 2, 29, 100, 2, 2, 34, 2, 2, 2, 2, 2, 98, 31, 2, 33, 2, 58, 14, 2, 2, 2, 2, 365, 2, 2, 2, 356, 346, 2, 2, 2, 63, 29, 93, 11, 2, 11, 2, 33, 2, 58, 54, 2, 431, 748, 2, 32, 2, 16, 11, 94, 2, 10, 10, 2, 993, 2, 2, 2, 2, 2, 2, 2, 2, 847, 2, 2, 121, 31, 2, 27, 86, 2, 2, 16, 2, 465, 993, 2, 2, 573, 17, 2, 42, 2, 2, 37, 473, 2, 711, 2, 2, 2, 328, 212, 70, 30, 258, 11, 220, 32, 2, 108, 21, 133, 12, 2, 55, 465, 849, 2, 53, 33, 2, 2, 37, 70, 2, 2, 2, 2, 74, 476, 37, 62, 91, 2, 169, 2, 2, 2, 146, 655, 2, 2, 258, 12, 184, 2, 546, 2, 849, 2, 2, 2, 22, 2, 18, 631, 2, 797, 2, 2, 2, 71, 348, 425, 2, 2, 19, 2, 2, 2, 11, 661, 2, 339, 2, 2, 2, 2, 2, 2, 2, 10, 10, 263, 787, 2, 270, 11, 2, 2, 2, 2, 2, 121, 2, 2, 26, 2, 19, 68, 2, 2, 28, 446, 2, 318, 2, 2, 67, 51, 36, 70, 81, 2, 2, 2, 36, 2, 2, 2, 2, 18, 2, 711, 2, 2, 26, 2, 2, 11, 14, 636, 720, 12, 426, 28, 77, 776, 2, 97, 38, 111, 2, 2, 168, 2, 2, 137, 2, 18, 27, 173, 2, 2, 17, 2, 2, 428, 2, 232, 11, 2, 2, 37, 272, 40, 2, 247, 30, 656, 2, 2, 54, 2, 2, 98, 2, 2, 40, 558, 37, 2, 98, 2, 2, 2, 15, 14, 2, 57, 2, 2, 2, 2, 275, 711, 2, 2, 2, 98, 2, 2, 10, 10, 2, 19, 14, 2, 267, 162, 711, 37, 2, 752, 98, 2, 2, 2, 90, 19, 2, 2, 2, 2, 2, 2, 2, 2, 2, 930, 2, 508, 90, 2, 2, 2, 2, 2, 17, 2, 2, 2, 2, 2, 2, 2, 189, 2, 2, 2, 2, 2, 2, 2, 95, 271, 23, 2, 2, 2, 2, 2, 33, 2, 2, 425, 2, 2, 2, 2, 2, 2, 2, 2, 469, 2, 2, 54, 2, 150, 2, 2, 280, 53, 2, 2, 18, 339, 29, 2, 27, 2, 2, 2, 68, 2, 19, 2, 2, 2, 2, 2, 263, 65, 2, 34, 2, 2, 2, 43, 159, 29, 2, 2, 2, 387, 73, 195, 584, 10, 10, 2, 2, 58, 810, 54, 14, 2, 117, 22, 16, 93, 2, 2, 2, 192, 15, 12, 16, 93, 34, 2, 2, 2, 33, 2, 2, 2, 15, 2, 2, 2, 325, 12, 62, 30, 776, 2, 67, 14, 17, 2, 2, 44, 148, 687, 2, 203, 42, 203, 24, 28, 69, 2, 2, 11, 330, 54, 29, 93, 2, 21, 845, 2, 27, 2, 2, 819, 2, 22, 2, 17, 2, 2, 787, 2, 2, 2, 2, 100, 30, 2, 2, 2, 2, 2, 42, 2, 11, 2, 2, 42, 101, 704, 2, 101, 999, 15, 2, 94, 2, 180, 2, 2, 2, 34, 2, 45, 2, 2, 22, 60, 2, 2, 31, 11, 94, 2, 96, 21, 94, 749, 2, 57, 975]),\n",
              "         ...,\n",
              "         list([2, 13, 2, 15, 2, 135, 14, 2, 35, 32, 46, 394, 20, 62, 30, 2, 21, 45, 184, 78, 2, 2, 910, 769, 2, 2, 395, 2, 2, 2, 11, 119, 2, 89, 2, 2, 116, 218, 78, 21, 407, 100, 30, 128, 262, 15, 2, 185, 2, 284, 2, 2, 37, 315, 2, 226, 20, 272, 2, 40, 29, 152, 60, 181, 2, 30, 50, 553, 362, 80, 119, 12, 21, 846, 2]),\n",
              "         list([2, 11, 119, 241, 2, 2, 840, 20, 12, 468, 15, 94, 2, 562, 791, 39, 2, 86, 107, 2, 97, 14, 31, 33, 2, 2, 2, 743, 46, 2, 2, 2, 2, 2, 768, 47, 2, 79, 90, 145, 164, 162, 50, 2, 501, 119, 2, 2, 2, 78, 232, 15, 16, 224, 11, 2, 333, 20, 2, 985, 200, 2, 2, 2, 2, 2, 2, 79, 357, 2, 20, 47, 220, 57, 206, 139, 11, 12, 2, 55, 117, 212, 13, 2, 92, 124, 51, 45, 2, 71, 536, 13, 520, 14, 20, 2, 2, 2, 470]),\n",
              "         list([2, 2, 52, 2, 430, 22, 2, 220, 2, 2, 28, 2, 519, 2, 2, 769, 15, 47, 2, 2, 2, 2, 114, 2, 33, 222, 31, 55, 184, 704, 2, 2, 19, 346, 2, 2, 2, 364, 350, 2, 184, 2, 2, 133, 2, 11, 2, 2, 21, 2, 2, 2, 570, 50, 2, 2, 2, 2, 2, 17, 2, 2, 2, 21, 17, 2, 2, 232, 2, 2, 29, 266, 56, 96, 346, 194, 308, 2, 194, 21, 29, 218, 2, 19, 2, 78, 173, 2, 27, 2, 2, 2, 718, 2, 2, 2, 2, 17, 210, 2, 2, 2, 47, 77, 395, 14, 172, 173, 18, 2, 2, 2, 82, 127, 27, 173, 11, 2, 392, 217, 21, 50, 2, 57, 65, 12, 2, 53, 40, 35, 390, 2, 11, 2, 2, 2, 2, 314, 74, 2, 792, 22, 2, 19, 714, 727, 2, 382, 2, 91, 2, 439, 19, 14, 20, 2, 2, 2, 2, 2, 756, 25, 124, 2, 31, 12, 16, 93, 804, 34, 2, 2])],\n",
              "        dtype=object),\n",
              "  array([0, 1, 1, ..., 0, 0, 0])))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UBDAFt0FJDJ3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d698f2bd-0a67-4c2b-9f94-f0a2dbd97a74"
      },
      "source": [
        "# Limit the sequence lengths to 500 using maxlen\n",
        "\n",
        "imdb.load_data(maxlen=500)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/imdb.py:159: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/imdb.py:160: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((array([list([1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 22665, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 21631, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 19193, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 10311, 8, 4, 107, 117, 5952, 15, 256, 4, 31050, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 12118, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]),\n",
              "         list([1, 194, 1153, 194, 8255, 78, 228, 5, 6, 1463, 4369, 5012, 134, 26, 4, 715, 8, 118, 1634, 14, 394, 20, 13, 119, 954, 189, 102, 5, 207, 110, 3103, 21, 14, 69, 188, 8, 30, 23, 7, 4, 249, 126, 93, 4, 114, 9, 2300, 1523, 5, 647, 4, 116, 9, 35, 8163, 4, 229, 9, 340, 1322, 4, 118, 9, 4, 130, 4901, 19, 4, 1002, 5, 89, 29, 952, 46, 37, 4, 455, 9, 45, 43, 38, 1543, 1905, 398, 4, 1649, 26, 6853, 5, 163, 11, 3215, 10156, 4, 1153, 9, 194, 775, 7, 8255, 11596, 349, 2637, 148, 605, 15358, 8003, 15, 123, 125, 68, 23141, 6853, 15, 349, 165, 4362, 98, 5, 4, 228, 9, 43, 36893, 1157, 15, 299, 120, 5, 120, 174, 11, 220, 175, 136, 50, 9, 4373, 228, 8255, 5, 25249, 656, 245, 2350, 5, 4, 9837, 131, 152, 491, 18, 46151, 32, 7464, 1212, 14, 9, 6, 371, 78, 22, 625, 64, 1382, 9, 8, 168, 145, 23, 4, 1690, 15, 16, 4, 1355, 5, 28, 6, 52, 154, 462, 33, 89, 78, 285, 16, 145, 95]),\n",
              "         list([1, 14, 47, 8, 30, 31, 7, 4, 249, 108, 7, 4, 5974, 54, 61, 369, 13, 71, 149, 14, 22, 112, 4, 2401, 311, 12, 16, 3711, 33, 75, 43, 1829, 296, 4, 86, 320, 35, 534, 19, 263, 4821, 1301, 4, 1873, 33, 89, 78, 12, 66, 16, 4, 360, 7, 4, 58, 316, 334, 11, 4, 1716, 43, 645, 662, 8, 257, 85, 1200, 42, 1228, 2578, 83, 68, 3912, 15, 36, 165, 1539, 278, 36, 69, 44076, 780, 8, 106, 14, 6905, 1338, 18, 6, 22, 12, 215, 28, 610, 40, 6, 87, 326, 23, 2300, 21, 23, 22, 12, 272, 40, 57, 31, 11, 4, 22, 47, 6, 2307, 51, 9, 170, 23, 595, 116, 595, 1352, 13, 191, 79, 638, 89, 51428, 14, 9, 8, 106, 607, 624, 35, 534, 6, 227, 7, 129, 113]),\n",
              "         ...,\n",
              "         list([1, 11, 6, 230, 245, 6401, 9, 6, 1225, 446, 86527, 45, 2174, 84, 8322, 4007, 21, 4, 912, 84, 14532, 325, 725, 134, 15271, 1715, 84, 5, 36, 28, 57, 1099, 21, 8, 140, 8, 703, 5, 11656, 84, 56, 18, 1644, 14, 9, 31, 7, 4, 9406, 1209, 2295, 26094, 1008, 18, 6, 20, 207, 110, 563, 12, 8, 2901, 17793, 8, 97, 6, 20, 53, 4767, 74, 4, 460, 364, 1273, 29, 270, 11, 960, 108, 45, 40, 29, 2961, 395, 11, 6, 4065, 500, 7, 14492, 89, 364, 70, 29, 140, 4, 64, 4780, 11, 4, 2678, 26, 178, 4, 529, 443, 17793, 5, 27, 710, 117, 74936, 8123, 165, 47, 84, 37, 131, 818, 14, 595, 10, 10, 61, 1242, 1209, 10, 10, 288, 2260, 1702, 34, 2901, 17793, 4, 65, 496, 4, 231, 7, 790, 5, 6, 320, 234, 2766, 234, 1119, 1574, 7, 496, 4, 139, 929, 2901, 17793, 7750, 5, 4241, 18, 4, 8497, 13164, 250, 11, 1818, 7561, 4, 4217, 5408, 747, 1115, 372, 1890, 1006, 541, 9303, 7, 4, 59, 11027, 4, 3586, 22459]),\n",
              "         list([1, 1446, 7079, 69, 72, 3305, 13, 610, 930, 8, 12, 582, 23, 5, 16, 484, 685, 54, 349, 11, 4120, 2959, 45, 58, 1466, 13, 197, 12, 16, 43, 23, 21469, 5, 62, 30, 145, 402, 11, 4131, 51, 575, 32, 61, 369, 71, 66, 770, 12, 1054, 75, 100, 2198, 8, 4, 105, 37, 69, 147, 712, 75, 3543, 44, 257, 390, 5, 69, 263, 514, 105, 50, 286, 1814, 23, 4, 123, 13, 161, 40, 5, 421, 4, 116, 16, 897, 13, 40691, 40, 319, 5872, 112, 6700, 11, 4803, 121, 25, 70, 3468, 4, 719, 3798, 13, 18, 31, 62, 40, 8, 7200, 4, 29455, 7, 14, 123, 5, 942, 25, 8, 721, 12, 145, 5, 202, 12, 160, 580, 202, 12, 6, 52, 58, 11418, 92, 401, 728, 12, 39, 14, 251, 8, 15, 251, 5, 21213, 12, 38, 84, 80, 124, 12, 9, 23]),\n",
              "         list([1, 17, 6, 194, 337, 7, 4, 204, 22, 45, 254, 8, 106, 14, 123, 4, 12815, 270, 14437, 5, 16923, 12255, 732, 2098, 101, 405, 39, 14, 1034, 4, 1310, 9, 115, 50, 305, 12, 47, 4, 168, 5, 235, 7, 38, 111, 699, 102, 7, 4, 4039, 9245, 9, 24, 6, 78, 1099, 17, 2345, 16553, 21, 27, 9685, 6139, 5, 29043, 1603, 92, 1183, 4, 1310, 7, 4, 204, 42, 97, 90, 35, 221, 109, 29, 127, 27, 118, 8, 97, 12, 157, 21, 6789, 85010, 9, 6, 66, 78, 1099, 4, 631, 1191, 5, 2642, 272, 191, 1070, 6, 7585, 8, 2197, 70907, 10755, 544, 5, 383, 1271, 848, 1468, 12183, 497, 16876, 8, 1597, 8778, 19280, 21, 60, 27, 239, 9, 43, 8368, 209, 405, 10, 10, 12, 764, 40, 4, 248, 20, 12, 16, 5, 174, 1791, 72, 7, 51, 6, 1739, 22, 4, 204, 131, 9])],\n",
              "        dtype=object), array([1, 0, 0, ..., 0, 1, 0])),\n",
              " (array([list([1, 591, 202, 14, 31, 6, 717, 10, 10, 18142, 10698, 5, 4, 360, 7, 4, 177, 5760, 394, 354, 4, 123, 9, 1035, 1035, 1035, 10, 10, 13, 92, 124, 89, 488, 7944, 100, 28, 1668, 14, 31, 23, 27, 7479, 29, 220, 468, 8, 124, 14, 286, 170, 8, 157, 46, 5, 27, 239, 16, 179, 15387, 38, 32, 25, 7944, 451, 202, 14, 6, 717]),\n",
              "         list([1, 14, 22, 3443, 6, 176, 7, 5063, 88, 12, 2679, 23, 1310, 5, 109, 943, 4, 114, 9, 55, 606, 5, 111, 7, 4, 139, 193, 273, 23, 4, 172, 270, 11, 7216, 10626, 4, 8463, 2801, 109, 1603, 21, 4, 22, 3861, 8, 6, 1193, 1330, 10, 10, 4, 105, 987, 35, 841, 16873, 19, 861, 1074, 5, 1987, 17975, 45, 55, 221, 15, 670, 5304, 526, 14, 1069, 4, 405, 5, 2438, 7, 27, 85, 108, 131, 4, 5045, 5304, 3884, 405, 9, 3523, 133, 5, 50, 13, 104, 51, 66, 166, 14, 22, 157, 9, 4, 530, 239, 34, 8463, 2801, 45, 407, 31, 7, 41, 3778, 105, 21, 59, 299, 12, 38, 950, 5, 4521, 15, 45, 629, 488, 2733, 127, 6, 52, 292, 17, 4, 6936, 185, 132, 1988, 5304, 1799, 488, 2693, 47, 6, 392, 173, 4, 21686, 4378, 270, 2352, 4, 1500, 7, 4, 65, 55, 73, 11, 346, 14, 20, 9, 6, 976, 2078, 7, 5293, 861, 12746, 5, 4182, 30, 3127, 23651, 56, 4, 841, 5, 990, 692, 8, 4, 1669, 398, 229, 10, 10, 13, 2822, 670, 5304, 14, 9, 31, 7, 27, 111, 108, 15, 2033, 19, 7836, 1429, 875, 551, 14, 22, 9, 1193, 21, 45, 4829, 5, 45, 252, 8, 12508, 6, 565, 921, 3639, 39, 4, 529, 48, 25, 181, 8, 67, 35, 1732, 22, 49, 238, 60, 135, 1162, 14, 9, 290, 4, 58, 10, 10, 472, 45, 55, 878, 8, 169, 11, 374, 5687, 25, 203, 28, 8, 818, 12, 125, 4, 3077]),\n",
              "         list([1, 13, 1228, 119, 14, 552, 7, 20, 190, 14, 58, 13, 258, 546, 1786, 8, 1968, 4, 268, 237, 13, 191, 81, 15, 13, 80, 43, 3824, 44, 12, 14, 16, 427, 3192, 4, 183, 15, 593, 19, 4, 351, 362, 26, 55, 646, 21, 4, 1239, 84, 26, 1557, 3755, 13, 244, 6, 2071, 132, 184, 194, 5, 13, 70, 4478, 546, 73, 190, 13, 62, 24, 81, 320, 4, 538, 4, 117, 250, 127, 11, 14, 20, 82, 4, 452, 11, 14, 20, 9, 8654, 19, 41, 476, 8, 4, 213, 7, 9185, 13, 657, 13, 286, 38, 1612, 44, 41, 5, 41, 1729, 88, 13, 62, 28, 900, 510, 4, 509, 51, 6, 612, 59, 16, 193, 61, 4666, 5, 702, 930, 143, 285, 25, 67, 41, 81, 366, 4, 130, 82, 9, 259, 334, 397, 1195, 7, 149, 102, 15, 26, 814, 38, 465, 1627, 31, 70, 983, 67, 51, 9, 112, 814, 17, 35, 311, 75, 26, 11649, 574, 19, 4, 1729, 23, 4, 268, 38, 95, 138, 4, 609, 191, 75, 28, 314, 1772]),\n",
              "         ...,\n",
              "         list([1, 13, 1408, 15, 8, 135, 14, 9, 35, 32, 46, 394, 20, 62, 30, 5093, 21, 45, 184, 78, 4, 1492, 910, 769, 2290, 2515, 395, 4257, 5, 1454, 11, 119, 16946, 89, 1036, 4, 116, 218, 78, 21, 407, 100, 30, 128, 262, 15, 7, 185, 2280, 284, 1842, 60664, 37, 315, 4, 226, 20, 272, 2942, 40, 29, 152, 60, 181, 8, 30, 50, 553, 362, 80, 119, 12, 21, 846, 5518]),\n",
              "         list([1, 11, 119, 241, 9, 4, 840, 20, 12, 468, 15, 94, 3684, 562, 791, 39, 4, 86, 107, 8, 97, 14, 31, 33, 4, 2960, 7, 743, 46, 1028, 9, 3531, 5, 4, 768, 47, 8, 79, 90, 145, 164, 162, 50, 6, 501, 119, 7, 9, 4, 78, 232, 15, 16, 224, 11, 4, 333, 20, 4, 985, 200, 5, 28739, 5, 9, 1861, 8, 79, 357, 4, 20, 47, 220, 57, 206, 139, 11, 12, 5, 55, 117, 212, 13, 1276, 92, 124, 51, 45, 1188, 71, 536, 13, 520, 14, 20, 6, 2302, 7, 470]),\n",
              "         list([1, 6, 52, 7465, 430, 22, 9, 220, 2594, 8, 28, 24357, 519, 3227, 6, 769, 15, 47, 6, 3482, 4067, 8, 114, 5, 33, 222, 31, 55, 184, 704, 5586, 18020, 19, 346, 3153, 5, 6, 364, 350, 4, 184, 5586, 9, 133, 1810, 11, 5417, 13226, 21, 4, 7298, 42657, 570, 50, 2005, 2643, 9, 6, 1249, 17, 6, 25194, 27803, 21, 17, 6, 1211, 232, 1138, 2249, 29, 266, 56, 96, 346, 194, 308, 9, 194, 21, 29, 218, 1078, 19, 4, 78, 173, 7, 27, 20067, 5698, 3406, 718, 21264, 9, 6, 6907, 17, 210, 5, 3281, 5677, 47, 77, 395, 14, 172, 173, 18, 2740, 2931, 4517, 82, 127, 27, 173, 11, 6, 392, 217, 21, 50, 9, 57, 65, 12, 14274, 53, 40, 35, 390, 7, 11, 4, 3567, 7, 4, 314, 74, 6, 792, 22, 16261, 19, 714, 727, 5205, 382, 4, 91, 6533, 439, 19, 14, 20, 9, 1441, 5805, 1118, 4, 756, 25, 124, 4, 31, 12, 16, 93, 804, 34, 2005, 2643])],\n",
              "        dtype=object),\n",
              "  array([0, 1, 0, ..., 0, 0, 0])))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DI-Nr897LorW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f168fb4f-97c3-413d-e064-5476078613e8"
      },
      "source": [
        " # Use '1' as the character that indicates the start of a sequence\n",
        "\n",
        "imdb.load_data(start_char=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/imdb.py:159: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/imdb.py:160: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((array([list([1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 22665, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 21631, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 19193, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 10311, 8, 4, 107, 117, 5952, 15, 256, 4, 31050, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 12118, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]),\n",
              "         list([1, 194, 1153, 194, 8255, 78, 228, 5, 6, 1463, 4369, 5012, 134, 26, 4, 715, 8, 118, 1634, 14, 394, 20, 13, 119, 954, 189, 102, 5, 207, 110, 3103, 21, 14, 69, 188, 8, 30, 23, 7, 4, 249, 126, 93, 4, 114, 9, 2300, 1523, 5, 647, 4, 116, 9, 35, 8163, 4, 229, 9, 340, 1322, 4, 118, 9, 4, 130, 4901, 19, 4, 1002, 5, 89, 29, 952, 46, 37, 4, 455, 9, 45, 43, 38, 1543, 1905, 398, 4, 1649, 26, 6853, 5, 163, 11, 3215, 10156, 4, 1153, 9, 194, 775, 7, 8255, 11596, 349, 2637, 148, 605, 15358, 8003, 15, 123, 125, 68, 23141, 6853, 15, 349, 165, 4362, 98, 5, 4, 228, 9, 43, 36893, 1157, 15, 299, 120, 5, 120, 174, 11, 220, 175, 136, 50, 9, 4373, 228, 8255, 5, 25249, 656, 245, 2350, 5, 4, 9837, 131, 152, 491, 18, 46151, 32, 7464, 1212, 14, 9, 6, 371, 78, 22, 625, 64, 1382, 9, 8, 168, 145, 23, 4, 1690, 15, 16, 4, 1355, 5, 28, 6, 52, 154, 462, 33, 89, 78, 285, 16, 145, 95]),\n",
              "         list([1, 14, 47, 8, 30, 31, 7, 4, 249, 108, 7, 4, 5974, 54, 61, 369, 13, 71, 149, 14, 22, 112, 4, 2401, 311, 12, 16, 3711, 33, 75, 43, 1829, 296, 4, 86, 320, 35, 534, 19, 263, 4821, 1301, 4, 1873, 33, 89, 78, 12, 66, 16, 4, 360, 7, 4, 58, 316, 334, 11, 4, 1716, 43, 645, 662, 8, 257, 85, 1200, 42, 1228, 2578, 83, 68, 3912, 15, 36, 165, 1539, 278, 36, 69, 44076, 780, 8, 106, 14, 6905, 1338, 18, 6, 22, 12, 215, 28, 610, 40, 6, 87, 326, 23, 2300, 21, 23, 22, 12, 272, 40, 57, 31, 11, 4, 22, 47, 6, 2307, 51, 9, 170, 23, 595, 116, 595, 1352, 13, 191, 79, 638, 89, 51428, 14, 9, 8, 106, 607, 624, 35, 534, 6, 227, 7, 129, 113]),\n",
              "         ...,\n",
              "         list([1, 11, 6, 230, 245, 6401, 9, 6, 1225, 446, 86527, 45, 2174, 84, 8322, 4007, 21, 4, 912, 84, 14532, 325, 725, 134, 15271, 1715, 84, 5, 36, 28, 57, 1099, 21, 8, 140, 8, 703, 5, 11656, 84, 56, 18, 1644, 14, 9, 31, 7, 4, 9406, 1209, 2295, 26094, 1008, 18, 6, 20, 207, 110, 563, 12, 8, 2901, 17793, 8, 97, 6, 20, 53, 4767, 74, 4, 460, 364, 1273, 29, 270, 11, 960, 108, 45, 40, 29, 2961, 395, 11, 6, 4065, 500, 7, 14492, 89, 364, 70, 29, 140, 4, 64, 4780, 11, 4, 2678, 26, 178, 4, 529, 443, 17793, 5, 27, 710, 117, 74936, 8123, 165, 47, 84, 37, 131, 818, 14, 595, 10, 10, 61, 1242, 1209, 10, 10, 288, 2260, 1702, 34, 2901, 17793, 4, 65, 496, 4, 231, 7, 790, 5, 6, 320, 234, 2766, 234, 1119, 1574, 7, 496, 4, 139, 929, 2901, 17793, 7750, 5, 4241, 18, 4, 8497, 13164, 250, 11, 1818, 7561, 4, 4217, 5408, 747, 1115, 372, 1890, 1006, 541, 9303, 7, 4, 59, 11027, 4, 3586, 22459]),\n",
              "         list([1, 1446, 7079, 69, 72, 3305, 13, 610, 930, 8, 12, 582, 23, 5, 16, 484, 685, 54, 349, 11, 4120, 2959, 45, 58, 1466, 13, 197, 12, 16, 43, 23, 21469, 5, 62, 30, 145, 402, 11, 4131, 51, 575, 32, 61, 369, 71, 66, 770, 12, 1054, 75, 100, 2198, 8, 4, 105, 37, 69, 147, 712, 75, 3543, 44, 257, 390, 5, 69, 263, 514, 105, 50, 286, 1814, 23, 4, 123, 13, 161, 40, 5, 421, 4, 116, 16, 897, 13, 40691, 40, 319, 5872, 112, 6700, 11, 4803, 121, 25, 70, 3468, 4, 719, 3798, 13, 18, 31, 62, 40, 8, 7200, 4, 29455, 7, 14, 123, 5, 942, 25, 8, 721, 12, 145, 5, 202, 12, 160, 580, 202, 12, 6, 52, 58, 11418, 92, 401, 728, 12, 39, 14, 251, 8, 15, 251, 5, 21213, 12, 38, 84, 80, 124, 12, 9, 23]),\n",
              "         list([1, 17, 6, 194, 337, 7, 4, 204, 22, 45, 254, 8, 106, 14, 123, 4, 12815, 270, 14437, 5, 16923, 12255, 732, 2098, 101, 405, 39, 14, 1034, 4, 1310, 9, 115, 50, 305, 12, 47, 4, 168, 5, 235, 7, 38, 111, 699, 102, 7, 4, 4039, 9245, 9, 24, 6, 78, 1099, 17, 2345, 16553, 21, 27, 9685, 6139, 5, 29043, 1603, 92, 1183, 4, 1310, 7, 4, 204, 42, 97, 90, 35, 221, 109, 29, 127, 27, 118, 8, 97, 12, 157, 21, 6789, 85010, 9, 6, 66, 78, 1099, 4, 631, 1191, 5, 2642, 272, 191, 1070, 6, 7585, 8, 2197, 70907, 10755, 544, 5, 383, 1271, 848, 1468, 12183, 497, 16876, 8, 1597, 8778, 19280, 21, 60, 27, 239, 9, 43, 8368, 209, 405, 10, 10, 12, 764, 40, 4, 248, 20, 12, 16, 5, 174, 1791, 72, 7, 51, 6, 1739, 22, 4, 204, 131, 9])],\n",
              "        dtype=object), array([1, 0, 0, ..., 0, 1, 0])),\n",
              " (array([list([1, 591, 202, 14, 31, 6, 717, 10, 10, 18142, 10698, 5, 4, 360, 7, 4, 177, 5760, 394, 354, 4, 123, 9, 1035, 1035, 1035, 10, 10, 13, 92, 124, 89, 488, 7944, 100, 28, 1668, 14, 31, 23, 27, 7479, 29, 220, 468, 8, 124, 14, 286, 170, 8, 157, 46, 5, 27, 239, 16, 179, 15387, 38, 32, 25, 7944, 451, 202, 14, 6, 717]),\n",
              "         list([1, 14, 22, 3443, 6, 176, 7, 5063, 88, 12, 2679, 23, 1310, 5, 109, 943, 4, 114, 9, 55, 606, 5, 111, 7, 4, 139, 193, 273, 23, 4, 172, 270, 11, 7216, 10626, 4, 8463, 2801, 109, 1603, 21, 4, 22, 3861, 8, 6, 1193, 1330, 10, 10, 4, 105, 987, 35, 841, 16873, 19, 861, 1074, 5, 1987, 17975, 45, 55, 221, 15, 670, 5304, 526, 14, 1069, 4, 405, 5, 2438, 7, 27, 85, 108, 131, 4, 5045, 5304, 3884, 405, 9, 3523, 133, 5, 50, 13, 104, 51, 66, 166, 14, 22, 157, 9, 4, 530, 239, 34, 8463, 2801, 45, 407, 31, 7, 41, 3778, 105, 21, 59, 299, 12, 38, 950, 5, 4521, 15, 45, 629, 488, 2733, 127, 6, 52, 292, 17, 4, 6936, 185, 132, 1988, 5304, 1799, 488, 2693, 47, 6, 392, 173, 4, 21686, 4378, 270, 2352, 4, 1500, 7, 4, 65, 55, 73, 11, 346, 14, 20, 9, 6, 976, 2078, 7, 5293, 861, 12746, 5, 4182, 30, 3127, 23651, 56, 4, 841, 5, 990, 692, 8, 4, 1669, 398, 229, 10, 10, 13, 2822, 670, 5304, 14, 9, 31, 7, 27, 111, 108, 15, 2033, 19, 7836, 1429, 875, 551, 14, 22, 9, 1193, 21, 45, 4829, 5, 45, 252, 8, 12508, 6, 565, 921, 3639, 39, 4, 529, 48, 25, 181, 8, 67, 35, 1732, 22, 49, 238, 60, 135, 1162, 14, 9, 290, 4, 58, 10, 10, 472, 45, 55, 878, 8, 169, 11, 374, 5687, 25, 203, 28, 8, 818, 12, 125, 4, 3077]),\n",
              "         list([1, 111, 748, 4368, 1133, 33782, 24563, 4, 87, 1551, 1262, 7, 31, 318, 9459, 7, 4, 498, 5076, 748, 63, 29, 5161, 220, 686, 10941, 5, 17, 12, 575, 220, 2507, 17, 6, 185, 132, 24563, 16, 53, 928, 11, 51278, 74, 4, 438, 21, 27, 10044, 589, 8, 22, 107, 20123, 19550, 997, 1638, 8, 35, 2076, 9019, 11, 22, 231, 54, 29, 1706, 29, 100, 18995, 2425, 34, 12998, 8738, 48078, 5, 19353, 98, 31, 2122, 33, 6, 58, 14, 3808, 1638, 8, 4, 365, 7, 2789, 3761, 356, 346, 4, 27608, 1060, 63, 29, 93, 11, 5421, 11, 15236, 33, 6, 58, 54, 1270, 431, 748, 7, 32, 2580, 16, 11, 94, 19469, 10, 10, 4, 993, 45222, 7, 4, 1766, 2634, 2164, 24563, 8, 847, 8, 1450, 121, 31, 7, 27, 86, 2663, 10760, 16, 6, 465, 993, 2006, 30995, 573, 17, 61862, 42, 4, 17345, 37, 473, 6, 711, 6, 8869, 7, 328, 212, 70, 30, 258, 11, 220, 32, 7, 108, 21, 133, 12, 9, 55, 465, 849, 3711, 53, 33, 2071, 1969, 37, 70, 1144, 4, 5940, 1409, 74, 476, 37, 62, 91, 1329, 169, 4, 1330, 10104, 146, 655, 2212, 5, 258, 12, 184, 10104, 546, 5, 849, 10333, 7, 4, 22, 1436, 18, 631, 1386, 797, 7, 4, 8712, 71, 348, 425, 4320, 1061, 19, 10288, 5, 12141, 11, 661, 8, 339, 17863, 4, 2455, 11434, 7, 4, 1962, 10, 10, 263, 787, 9, 270, 11, 6, 9466, 4, 61862, 48414, 121, 4, 5437, 26, 4434, 19, 68, 1372, 5, 28, 446, 6, 318, 7149, 8, 67, 51, 36, 70, 81, 8, 4392, 2294, 36, 1197, 8, 68411, 25399, 18, 6, 711, 4, 9909, 26, 10296, 1125, 11, 14, 636, 720, 12, 426, 28, 77, 776, 8, 97, 38, 111, 7489, 6175, 168, 1239, 5189, 137, 25399, 18, 27, 173, 9, 2399, 17, 6, 12397, 428, 14657, 232, 11, 4, 8014, 37, 272, 40, 2708, 247, 30, 656, 6, 13182, 54, 25399, 3292, 98, 6, 2840, 40, 558, 37, 6093, 98, 4, 17345, 1197, 15, 14, 9, 57, 4893, 5, 4659, 6, 275, 711, 7937, 25399, 3292, 98, 6, 31036, 10, 10, 6639, 19, 14, 10241, 267, 162, 711, 37, 5900, 752, 98, 4, 17345, 2378, 90, 19, 6, 73284, 7, 36744, 1810, 77553, 4, 4770, 3183, 930, 8, 508, 90, 4, 1317, 8, 4, 48414, 17, 15454, 3965, 1853, 4, 1494, 8, 4468, 189, 4, 31036, 6287, 5774, 4, 4770, 5, 95, 271, 23, 6, 7742, 6063, 21627, 5437, 33, 1526, 6, 425, 3155, 33697, 4535, 1636, 7, 4, 4669, 11966, 469, 4, 4552, 54, 4, 150, 5664, 17345, 280, 53, 68411, 25399, 18, 339, 29, 1978, 27, 7885, 5, 17303, 68, 1830, 19, 6571, 14605, 4, 1515, 7, 263, 65, 2132, 34, 6, 5680, 7489, 43, 159, 29, 9, 4706, 9, 387, 73, 195, 584, 10, 10, 1069, 4, 58, 810, 54, 14, 6078, 117, 22, 16, 93, 5, 1069, 4, 192, 15, 12, 16, 93, 34, 6, 1766, 28228, 33, 4, 5673, 7, 15, 18760, 9252, 3286, 325, 12, 62, 30, 776, 8, 67, 14, 17, 6, 12214, 44, 148, 687, 24563, 203, 42, 203, 24, 28, 69, 32157, 6676, 11, 330, 54, 29, 93, 61862, 21, 845, 14148, 27, 1099, 7, 819, 4, 22, 1407, 17, 6, 14967, 787, 7, 2460, 19569, 61862, 100, 30, 4, 3737, 3617, 3169, 2321, 42, 1898, 11, 4, 3814, 42, 101, 704, 7, 101, 999, 15, 1625, 94, 2926, 180, 5, 9, 9101, 34, 15205, 45, 6, 1429, 22, 60, 6, 1220, 31, 11, 94, 6408, 96, 21, 94, 749, 9, 57, 975]),\n",
              "         ...,\n",
              "         list([1, 13, 1408, 15, 8, 135, 14, 9, 35, 32, 46, 394, 20, 62, 30, 5093, 21, 45, 184, 78, 4, 1492, 910, 769, 2290, 2515, 395, 4257, 5, 1454, 11, 119, 16946, 89, 1036, 4, 116, 218, 78, 21, 407, 100, 30, 128, 262, 15, 7, 185, 2280, 284, 1842, 60664, 37, 315, 4, 226, 20, 272, 2942, 40, 29, 152, 60, 181, 8, 30, 50, 553, 362, 80, 119, 12, 21, 846, 5518]),\n",
              "         list([1, 11, 119, 241, 9, 4, 840, 20, 12, 468, 15, 94, 3684, 562, 791, 39, 4, 86, 107, 8, 97, 14, 31, 33, 4, 2960, 7, 743, 46, 1028, 9, 3531, 5, 4, 768, 47, 8, 79, 90, 145, 164, 162, 50, 6, 501, 119, 7, 9, 4, 78, 232, 15, 16, 224, 11, 4, 333, 20, 4, 985, 200, 5, 28739, 5, 9, 1861, 8, 79, 357, 4, 20, 47, 220, 57, 206, 139, 11, 12, 5, 55, 117, 212, 13, 1276, 92, 124, 51, 45, 1188, 71, 536, 13, 520, 14, 20, 6, 2302, 7, 470]),\n",
              "         list([1, 6, 52, 7465, 430, 22, 9, 220, 2594, 8, 28, 24357, 519, 3227, 6, 769, 15, 47, 6, 3482, 4067, 8, 114, 5, 33, 222, 31, 55, 184, 704, 5586, 18020, 19, 346, 3153, 5, 6, 364, 350, 4, 184, 5586, 9, 133, 1810, 11, 5417, 13226, 21, 4, 7298, 42657, 570, 50, 2005, 2643, 9, 6, 1249, 17, 6, 25194, 27803, 21, 17, 6, 1211, 232, 1138, 2249, 29, 266, 56, 96, 346, 194, 308, 9, 194, 21, 29, 218, 1078, 19, 4, 78, 173, 7, 27, 20067, 5698, 3406, 718, 21264, 9, 6, 6907, 17, 210, 5, 3281, 5677, 47, 77, 395, 14, 172, 173, 18, 2740, 2931, 4517, 82, 127, 27, 173, 11, 6, 392, 217, 21, 50, 9, 57, 65, 12, 14274, 53, 40, 35, 390, 7, 11, 4, 3567, 7, 4, 314, 74, 6, 792, 22, 16261, 19, 714, 727, 5205, 382, 4, 91, 6533, 439, 19, 14, 20, 9, 1441, 5805, 1118, 4, 756, 25, 124, 4, 31, 12, 16, 93, 804, 34, 2005, 2643])],\n",
              "        dtype=object),\n",
              "  array([0, 1, 1, ..., 0, 0, 0])))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AuBCKKGyJDJ7"
      },
      "source": [
        "#### Explore the dataset word index"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_gkaFf6MJDJ9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c8eb073-b3b5-418d-fb3e-fda7b5b80c8a"
      },
      "source": [
        "# Load the imdb word index using get_word_index()\n",
        "\n",
        "imdb_word_index = imdb.get_word_index()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n",
            "1646592/1641221 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EUzgAIoKJDKB"
      },
      "source": [
        "# View the word index as a dictionary,\n",
        "# accounting for index_from.\n",
        "\n",
        "index_from = 3\n",
        "imdb_word_index = {key: val + index_from for key, val in imdb_word_index.items()}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "huCi_QIzJDKL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24bf19a5-ab18-4c72-bb6e-947457bb3ea4"
      },
      "source": [
        "# Retrieve a specific word's index\n",
        "\n",
        "imdb_word_index['simpsonian']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "52256"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M9X4OO_FNGZx",
        "outputId": "0a3c6b50-3b37-4b4b-9cd5-89504a393187"
      },
      "source": [
        "imdb_word_index['the']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p7UkZwHiJDKU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d4705a6-dca8-4e41-83b3-2f546e7e238c"
      },
      "source": [
        "# View an input sentence\n",
        "\n",
        "inv_imdb_word_index = {val: key for key, val in imdb_word_index.items()}\n",
        "[inv_imdb_word_index[index] for index in x_train[0] if index > index_from]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['this',\n",
              " 'film',\n",
              " 'was',\n",
              " 'just',\n",
              " 'brilliant',\n",
              " 'casting',\n",
              " 'location',\n",
              " 'scenery',\n",
              " 'story',\n",
              " 'direction',\n",
              " \"everyone's\",\n",
              " 'really',\n",
              " 'suited',\n",
              " 'the',\n",
              " 'part',\n",
              " 'they',\n",
              " 'played',\n",
              " 'and',\n",
              " 'you',\n",
              " 'could',\n",
              " 'just',\n",
              " 'imagine',\n",
              " 'being',\n",
              " 'there',\n",
              " 'robert',\n",
              " \"redford's\",\n",
              " 'is',\n",
              " 'an',\n",
              " 'amazing',\n",
              " 'actor',\n",
              " 'and',\n",
              " 'now',\n",
              " 'the',\n",
              " 'same',\n",
              " 'being',\n",
              " 'director',\n",
              " \"norman's\",\n",
              " 'father',\n",
              " 'came',\n",
              " 'from',\n",
              " 'the',\n",
              " 'same',\n",
              " 'scottish',\n",
              " 'island',\n",
              " 'as',\n",
              " 'myself',\n",
              " 'so',\n",
              " 'i',\n",
              " 'loved',\n",
              " 'the',\n",
              " 'fact',\n",
              " 'there',\n",
              " 'was',\n",
              " 'a',\n",
              " 'real',\n",
              " 'connection',\n",
              " 'with',\n",
              " 'this',\n",
              " 'film',\n",
              " 'the',\n",
              " 'witty',\n",
              " 'remarks',\n",
              " 'throughout',\n",
              " 'the',\n",
              " 'film',\n",
              " 'were',\n",
              " 'great',\n",
              " 'it',\n",
              " 'was',\n",
              " 'just',\n",
              " 'brilliant',\n",
              " 'so',\n",
              " 'much',\n",
              " 'that',\n",
              " 'i',\n",
              " 'bought',\n",
              " 'the',\n",
              " 'film',\n",
              " 'as',\n",
              " 'soon',\n",
              " 'as',\n",
              " 'it',\n",
              " 'was',\n",
              " 'released',\n",
              " 'for',\n",
              " 'retail',\n",
              " 'and',\n",
              " 'would',\n",
              " 'recommend',\n",
              " 'it',\n",
              " 'to',\n",
              " 'everyone',\n",
              " 'to',\n",
              " 'watch',\n",
              " 'and',\n",
              " 'the',\n",
              " 'fly',\n",
              " 'fishing',\n",
              " 'was',\n",
              " 'amazing',\n",
              " 'really',\n",
              " 'cried',\n",
              " 'at',\n",
              " 'the',\n",
              " 'end',\n",
              " 'it',\n",
              " 'was',\n",
              " 'so',\n",
              " 'sad',\n",
              " 'and',\n",
              " 'you',\n",
              " 'know',\n",
              " 'what',\n",
              " 'they',\n",
              " 'say',\n",
              " 'if',\n",
              " 'you',\n",
              " 'cry',\n",
              " 'at',\n",
              " 'a',\n",
              " 'film',\n",
              " 'it',\n",
              " 'must',\n",
              " 'have',\n",
              " 'been',\n",
              " 'good',\n",
              " 'and',\n",
              " 'this',\n",
              " 'definitely',\n",
              " 'was',\n",
              " 'also',\n",
              " 'congratulations',\n",
              " 'to',\n",
              " 'the',\n",
              " 'two',\n",
              " 'little',\n",
              " \"boy's\",\n",
              " 'that',\n",
              " 'played',\n",
              " 'the',\n",
              " \"part's\",\n",
              " 'of',\n",
              " 'norman',\n",
              " 'and',\n",
              " 'paul',\n",
              " 'they',\n",
              " 'were',\n",
              " 'just',\n",
              " 'brilliant',\n",
              " 'children',\n",
              " 'are',\n",
              " 'often',\n",
              " 'left',\n",
              " 'out',\n",
              " 'of',\n",
              " 'the',\n",
              " 'praising',\n",
              " 'list',\n",
              " 'i',\n",
              " 'think',\n",
              " 'because',\n",
              " 'the',\n",
              " 'stars',\n",
              " 'that',\n",
              " 'play',\n",
              " 'them',\n",
              " 'all',\n",
              " 'grown',\n",
              " 'up',\n",
              " 'are',\n",
              " 'such',\n",
              " 'a',\n",
              " 'big',\n",
              " 'profile',\n",
              " 'for',\n",
              " 'the',\n",
              " 'whole',\n",
              " 'film',\n",
              " 'but',\n",
              " 'these',\n",
              " 'children',\n",
              " 'are',\n",
              " 'amazing',\n",
              " 'and',\n",
              " 'should',\n",
              " 'be',\n",
              " 'praised',\n",
              " 'for',\n",
              " 'what',\n",
              " 'they',\n",
              " 'have',\n",
              " 'done',\n",
              " \"don't\",\n",
              " 'you',\n",
              " 'think',\n",
              " 'the',\n",
              " 'whole',\n",
              " 'story',\n",
              " 'was',\n",
              " 'so',\n",
              " 'lovely',\n",
              " 'because',\n",
              " 'it',\n",
              " 'was',\n",
              " 'true',\n",
              " 'and',\n",
              " 'was',\n",
              " \"someone's\",\n",
              " 'life',\n",
              " 'after',\n",
              " 'all',\n",
              " 'that',\n",
              " 'was',\n",
              " 'shared',\n",
              " 'with',\n",
              " 'us',\n",
              " 'all']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qq2ID8wRJDKX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05c0152f-e5db-4637-8903-20059c01fe02"
      },
      "source": [
        "# Get the sentiment value\n",
        "\n",
        "y_train[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hcPUtmz-JDKZ"
      },
      "source": [
        "---\n",
        "<a id=\"coding_tutorial_2\"></a>\n",
        "## Padding and Masking Sequence Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5UggNd-8VLgV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1eb7765c-5a5a-4b4f-b043-1c4e8e96e351"
      },
      "source": [
        "# Load the imdb data set\n",
        "\n",
        "import tensorflow.keras.datasets.imdb as imdb\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17465344/17464789 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/imdb.py:159: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/imdb.py:160: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NuqWhXi-JDKa"
      },
      "source": [
        "#### Preprocess the data with padding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fWULtJ7CJDKe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7a66651-e1ab-4050-fe07-d44465566e11"
      },
      "source": [
        "# Inspect the input data shape\n",
        "\n",
        "x_train.shape"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25000,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OOts_k01JDKh"
      },
      "source": [
        "# Pad the inputs to the maximum length using maxlen\n",
        "\n",
        "padded_x_train = tf.keras.preprocessing.sequence.pad_sequences(x_train, maxlen=300, padding='post', truncating='pre')"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rNPiMGwDJDKk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5cc0bc4c-1b2f-45d1-a263-92cb65d1a8ac"
      },
      "source": [
        "# Inspect the output data shape\n",
        "\n",
        "padded_x_train.shape"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25000, 300)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AJt56letJDKn"
      },
      "source": [
        "#### Create a Masking layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZdoMdifYJDKo"
      },
      "source": [
        "# Import numpy \n",
        "\n",
        "import numpy as np"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v8LjX9QaJDKr"
      },
      "source": [
        "# Masking expects to see (batch, sequence, features)\n",
        "# Create a dummy feature dimension using expand_dims\n",
        "\n",
        "padded_x_train = np.expand_dims(padded_x_train, -1)\n",
        "#OR USE padded_x_train = padded_x_train[..., np.newaxis]\n",
        "\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uFrgXbDrJDKt"
      },
      "source": [
        "# Create a Masking layer \n",
        "\n",
        "tf_x_train = tf.convert_to_tensor(padded_x_train, dtype='float32')\n",
        "masking_layer = tf.keras.layers.Masking(mask_value=0.0)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9kkSzdHwJDKw"
      },
      "source": [
        "# Pass tf_x_train to it\n",
        "\n",
        "masked_x_train = masking_layer(tf_x_train)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MuStn9s0JDK0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b48f0b01-34eb-4a52-dbd4-bc7252a58386"
      },
      "source": [
        "# Look at the dataset\n",
        "\n",
        "tf_x_train"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(25000, 300, 1), dtype=float32, numpy=\n",
              "array([[[1.000e+00],\n",
              "        [1.400e+01],\n",
              "        [2.200e+01],\n",
              "        ...,\n",
              "        [0.000e+00],\n",
              "        [0.000e+00],\n",
              "        [0.000e+00]],\n",
              "\n",
              "       [[1.000e+00],\n",
              "        [1.940e+02],\n",
              "        [1.153e+03],\n",
              "        ...,\n",
              "        [0.000e+00],\n",
              "        [0.000e+00],\n",
              "        [0.000e+00]],\n",
              "\n",
              "       [[1.000e+00],\n",
              "        [1.400e+01],\n",
              "        [4.700e+01],\n",
              "        ...,\n",
              "        [0.000e+00],\n",
              "        [0.000e+00],\n",
              "        [0.000e+00]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[1.000e+00],\n",
              "        [1.100e+01],\n",
              "        [6.000e+00],\n",
              "        ...,\n",
              "        [0.000e+00],\n",
              "        [0.000e+00],\n",
              "        [0.000e+00]],\n",
              "\n",
              "       [[1.000e+00],\n",
              "        [1.446e+03],\n",
              "        [7.079e+03],\n",
              "        ...,\n",
              "        [0.000e+00],\n",
              "        [0.000e+00],\n",
              "        [0.000e+00]],\n",
              "\n",
              "       [[1.000e+00],\n",
              "        [1.700e+01],\n",
              "        [6.000e+00],\n",
              "        ...,\n",
              "        [0.000e+00],\n",
              "        [0.000e+00],\n",
              "        [0.000e+00]]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9GYG-UlOWJso"
      },
      "source": [
        "# tf_x_train._keras_mask"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O54DVLx4JDK7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3347ba82-b852-4a75-b6dd-7e0d0684c3be"
      },
      "source": [
        "# Look at the ._keras_mask for the dataset\n",
        "\n",
        "masked_x_train._keras_mask"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(25000, 300), dtype=bool, numpy=\n",
              "array([[ True,  True,  True, ..., False, False, False],\n",
              "       [ True,  True,  True, ..., False, False, False],\n",
              "       [ True,  True,  True, ..., False, False, False],\n",
              "       ...,\n",
              "       [ True,  True,  True, ..., False, False, False],\n",
              "       [ True,  True,  True, ..., False, False, False],\n",
              "       [ True,  True,  True, ..., False, False, False]])>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zo5rD5ZcJDK_"
      },
      "source": [
        "***\n",
        "<a id=\"coding_tutorial_3\"></a>\n",
        "## The Embedding layer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JCkBOM8mJDLA"
      },
      "source": [
        "#### Create and apply an `Embedding` layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D-esPcdDJDLJ"
      },
      "source": [
        "# Create an embedding layer using layers.Embedding\n",
        "# Specify input_dim, output_dim, input_length\n",
        "\n",
        "embedding_layer = tf.keras.layers.Embedding(input_dim = 501, output_dim = 16)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sf3B6HamJDLN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c85d7db-7a28-40d7-dd6f-1d5b20becbac"
      },
      "source": [
        "# Inspect an Embedding layer output for a fixed input\n",
        "# Expects an input of shape (batch, sequence, feature)\n",
        "\n",
        "sequence_of_indices = tf.constant([[[0], [1], [5], [500]]])\n",
        "sequence_of_embeddings = embedding_layer(sequence_of_indices)\n",
        "sequence_of_embeddings"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 4, 1, 16), dtype=float32, numpy=\n",
              "array([[[[ 0.00801451,  0.01410736,  0.00116625, -0.01825025,\n",
              "          -0.0384746 ,  0.00292188, -0.0087936 ,  0.01050808,\n",
              "           0.04017753, -0.00575219,  0.02110498, -0.00291384,\n",
              "          -0.03358424,  0.01205326, -0.00746052, -0.03850379]],\n",
              "\n",
              "        [[-0.00414885,  0.04440394,  0.03385458, -0.0151058 ,\n",
              "          -0.01384783, -0.02079234,  0.02053037, -0.02441523,\n",
              "           0.04315896,  0.00203233,  0.01651395, -0.0214765 ,\n",
              "          -0.02852841,  0.03200163, -0.03477192,  0.03553791]],\n",
              "\n",
              "        [[ 0.0348263 ,  0.04035548, -0.00569675,  0.03552583,\n",
              "           0.02546612, -0.00661119,  0.03668726, -0.02101131,\n",
              "           0.01074057,  0.0151335 , -0.01229682, -0.0384752 ,\n",
              "           0.02322042, -0.01271882, -0.02742435, -0.03294791]],\n",
              "\n",
              "        [[-0.02166654,  0.0129908 ,  0.03115931,  0.01896831,\n",
              "           0.02205174, -0.00571315,  0.04875709,  0.02377924,\n",
              "           0.04006238,  0.04366055, -0.04603047,  0.01078273,\n",
              "          -0.04021131,  0.04317986,  0.04155289, -0.00297077]]]],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ualmsaPpJDLV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75972205-6964-400c-d0bd-f6db0caa0d60"
      },
      "source": [
        "# Inspect the Embedding layer weights using get_weights()\n",
        "\n",
        "embedding_layer.get_weights()[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.00801451,  0.01410736,  0.00116625, ...,  0.01205326,\n",
              "        -0.00746052, -0.03850379],\n",
              "       [-0.00414885,  0.04440394,  0.03385458, ...,  0.03200163,\n",
              "        -0.03477192,  0.03553791],\n",
              "       [-0.04892945,  0.01380393,  0.01735872, ..., -0.00218714,\n",
              "        -0.02464647,  0.03643348],\n",
              "       ...,\n",
              "       [-0.02479465, -0.01801135, -0.04994736, ...,  0.01141549,\n",
              "        -0.02161474,  0.02225964],\n",
              "       [ 0.01950515,  0.02048507, -0.04489483, ..., -0.03850013,\n",
              "         0.01109854,  0.02306087],\n",
              "       [-0.02166654,  0.0129908 ,  0.03115931, ...,  0.04317986,\n",
              "         0.04155289, -0.00297077]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Wadlt3AJDLX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "14fbea81-7728-4829-feb4-9b9c7de1618d"
      },
      "source": [
        "# Get the embedding for the 14th index\n",
        "\n",
        "embedding_layer.get_weights()[0][14,:]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.03453961, -0.02127813, -0.04826909, -0.01245668,  0.02125387,\n",
              "        0.01800379,  0.02056428,  0.03300549, -0.00454269, -0.00098237,\n",
              "        0.04798057, -0.01275452,  0.03132631,  0.02252268, -0.00747663,\n",
              "       -0.00748044], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UFuhReOm9xF7"
      },
      "source": [
        "#### Create and apply an `Embedding` layer that uses `mask_zero=True`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nKYwKT_I-H2O"
      },
      "source": [
        "# Create a layer that uses the mask_zero kwarg\n",
        "\n",
        "mask_embedding_layer = tf.keras.layers.Embedding(input_dim=501, output_dim=16, mask_zero=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6hc1zx6A-H6R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59a1a848-c518-4ce8-d484-3662f43f2f6b"
      },
      "source": [
        "# Apply this layer to the sequence and see the _keras_mask property\n",
        "\n",
        "masked_sequence_of_embeddings = mask_embedding_layer(sequence_of_indices)\n",
        "masked_sequence_of_embeddings._keras_mask"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 4, 1), dtype=bool, numpy=\n",
              "array([[[False],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [ True]]])>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EUG6LF1MJDL0"
      },
      "source": [
        "---\n",
        "<a id=\"coding_tutorial_4\"></a>\n",
        "## The Embedding Projector"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zna3TCoTAu00"
      },
      "source": [
        "#### Mount Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qPKYrlepAxPV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2cb539ef-cd49-4217-a115-2dc0f819585b"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OBAX9ENDBFFE"
      },
      "source": [
        "#### Load and preprocess the IMDb data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yo5qBbDDBIdn"
      },
      "source": [
        "# A function to load and preprocess the IMDB dataset\n",
        "\n",
        "def get_and_pad_imdb_dataset(num_words=10000, maxlen=None, index_from=2):\n",
        "    from tensorflow.keras.datasets import imdb\n",
        "\n",
        "    # Load the reviews\n",
        "    (x_train, y_train), (x_test, y_test) = imdb.load_data(path='imdb.npz',\n",
        "                                                          num_words=num_words,\n",
        "                                                          skip_top=0,\n",
        "                                                          maxlen=maxlen,\n",
        "                                                          start_char=1,\n",
        "                                                          oov_char=2,\n",
        "                                                          index_from=index_from)\n",
        "\n",
        "    x_train = tf.keras.preprocessing.sequence.pad_sequences(x_train,\n",
        "                                                        maxlen=None,\n",
        "                                                        padding='pre',\n",
        "                                                        truncating='pre',\n",
        "                                                        value=0)\n",
        "    \n",
        "    x_test = tf.keras.preprocessing.sequence.pad_sequences(x_test,\n",
        "                                                           maxlen=None,\n",
        "                                                           padding='pre',\n",
        "                                                           truncating='pre',\n",
        "                                                           value=0)\n",
        "    return (x_train, y_train), (x_test, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RGpymnb2BIiR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "128cdc57-b29a-4800-ee95-28ef087c22e8"
      },
      "source": [
        "# Load the dataset\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = get_and_pad_imdb_dataset()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/imdb.py:159: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/imdb.py:160: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5EtU2vK0BLts"
      },
      "source": [
        "# A function to get the dataset word index\n",
        "\n",
        "def get_imdb_word_index(num_words=10000, index_from=2):\n",
        "    imdb_word_index = tf.keras.datasets.imdb.get_word_index(\n",
        "                                        path='imdb_word_index.json')\n",
        "    imdb_word_index = {key: value + index_from for\n",
        "                       key, value in imdb_word_index.items() if value <= num_words-index_from}\n",
        "    return imdb_word_index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vtkIEIdRBSxv"
      },
      "source": [
        "# Get the word index\n",
        "\n",
        "imdb_word_index = get_imdb_word_index()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ur2fp10YBS6T"
      },
      "source": [
        "# Swap the keys and values of the word index\n",
        "\n",
        "inv_imdb_word_index = {value:key for key, value in imdb_word_index.items()}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cquirCA8BS99",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "015eee6f-e380-4574-86fd-c3b46e037bc1"
      },
      "source": [
        "# View the first dataset example sentence\n",
        "\n",
        "[inv_imdb_word_index[index] for index in x_train[100] if index>2]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['i',\n",
              " 'am',\n",
              " 'a',\n",
              " 'great',\n",
              " 'fan',\n",
              " 'of',\n",
              " 'david',\n",
              " 'lynch',\n",
              " 'and',\n",
              " 'have',\n",
              " 'everything',\n",
              " 'that',\n",
              " \"he's\",\n",
              " 'made',\n",
              " 'on',\n",
              " 'dvd',\n",
              " 'except',\n",
              " 'for',\n",
              " 'hotel',\n",
              " 'room',\n",
              " 'the',\n",
              " '2',\n",
              " 'hour',\n",
              " 'twin',\n",
              " 'peaks',\n",
              " 'movie',\n",
              " 'so',\n",
              " 'when',\n",
              " 'i',\n",
              " 'found',\n",
              " 'out',\n",
              " 'about',\n",
              " 'this',\n",
              " 'i',\n",
              " 'immediately',\n",
              " 'grabbed',\n",
              " 'it',\n",
              " 'and',\n",
              " 'and',\n",
              " 'what',\n",
              " 'is',\n",
              " 'this',\n",
              " \"it's\",\n",
              " 'a',\n",
              " 'bunch',\n",
              " 'of',\n",
              " 'drawn',\n",
              " 'black',\n",
              " 'and',\n",
              " 'white',\n",
              " 'cartoons',\n",
              " 'that',\n",
              " 'are',\n",
              " 'loud',\n",
              " 'and',\n",
              " 'foul',\n",
              " 'mouthed',\n",
              " 'and',\n",
              " 'unfunny',\n",
              " 'maybe',\n",
              " 'i',\n",
              " \"don't\",\n",
              " 'know',\n",
              " \"what's\",\n",
              " 'good',\n",
              " 'but',\n",
              " 'maybe',\n",
              " 'this',\n",
              " 'is',\n",
              " 'just',\n",
              " 'a',\n",
              " 'bunch',\n",
              " 'of',\n",
              " 'crap',\n",
              " 'that',\n",
              " 'was',\n",
              " 'on',\n",
              " 'the',\n",
              " 'public',\n",
              " 'under',\n",
              " 'the',\n",
              " 'name',\n",
              " 'of',\n",
              " 'david',\n",
              " 'lynch',\n",
              " 'to',\n",
              " 'make',\n",
              " 'a',\n",
              " 'few',\n",
              " 'bucks',\n",
              " 'too',\n",
              " 'let',\n",
              " 'me',\n",
              " 'make',\n",
              " 'it',\n",
              " 'clear',\n",
              " 'that',\n",
              " 'i',\n",
              " \"didn't\",\n",
              " 'care',\n",
              " 'about',\n",
              " 'the',\n",
              " 'foul',\n",
              " 'language',\n",
              " 'part',\n",
              " 'but',\n",
              " 'had',\n",
              " 'to',\n",
              " 'keep',\n",
              " 'the',\n",
              " 'sound',\n",
              " 'because',\n",
              " 'my',\n",
              " 'neighbors',\n",
              " 'might',\n",
              " 'have',\n",
              " 'all',\n",
              " 'in',\n",
              " 'all',\n",
              " 'this',\n",
              " 'is',\n",
              " 'a',\n",
              " 'highly',\n",
              " 'disappointing',\n",
              " 'release',\n",
              " 'and',\n",
              " 'may',\n",
              " 'well',\n",
              " 'have',\n",
              " 'just',\n",
              " 'been',\n",
              " 'left',\n",
              " 'in',\n",
              " 'the',\n",
              " 'box',\n",
              " 'set',\n",
              " 'as',\n",
              " 'a',\n",
              " 'curiosity',\n",
              " 'i',\n",
              " 'highly',\n",
              " 'recommend',\n",
              " 'you',\n",
              " \"don't\",\n",
              " 'spend',\n",
              " 'your',\n",
              " 'money',\n",
              " 'on',\n",
              " 'this',\n",
              " '2',\n",
              " 'out',\n",
              " 'of',\n",
              " '10']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NrE0rpCVJDL1"
      },
      "source": [
        "#### Build an Embedding layer into a model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UPUfv9kjJDL1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b14336b6-117f-4001-8ff0-91f9ad400026"
      },
      "source": [
        "# Get the maximum token value\n",
        "\n",
        "max_index_value = max(imdb_word_index.values())\n",
        "max_index_value"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lO0CkecjJDL5"
      },
      "source": [
        "# Specify an embedding dimension\n",
        "\n",
        "embedding_dim = 16"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oFBZOlp3JDL7"
      },
      "source": [
        "# Build a model using Sequential:\n",
        "#     1. Embedding layer\n",
        "#     2. GlobalAveragePooling1D\n",
        "#     3. Dense\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "                             tf.keras.layers.Embedding(input_dim = max_index_value+1, output_dim=embedding_dim, mask_zero=False),\n",
        "                             tf.keras.layers.GlobalAveragePooling1D(),\n",
        "                             tf.keras.layers.Dense(units=1, activation='sigmoid')\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kw9qhtlPJDL9"
      },
      "source": [
        "# Functional API refresher: use the Model to build the same model\n",
        "\n",
        "inp_shape = (None, )\n",
        "review_sequence = tf.keras.Input(shape = inp_shape)\n",
        "embedding_sequence = tf.keras.layers.Embedding(input_dim=max_index_value+1, output_dim=embedding_dim, input_shape=(review_sequence.shape), mask_zero=False)(review_sequence)\n",
        "average_embedding = tf.keras.layers.GlobalAveragePooling1D()(embedding_sequence)\n",
        "positive_probability = tf.keras.layers.Dense(units=1, activation='sigmoid')(average_embedding)\n",
        "\n",
        "model = tf.keras.Model(inputs = review_sequence, outputs = positive_probability) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rf6oaEvTCKxV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b584f1e-2748-4561-bdb2-6cd66e43b463"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_56 (InputLayer)        [(None, None)]            0         \n",
            "_________________________________________________________________\n",
            "embedding_62 (Embedding)     (None, None, 16)          160016    \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d_59  (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dense_45 (Dense)             (None, 1)                 17        \n",
            "=================================================================\n",
            "Total params: 160,033\n",
            "Trainable params: 160,033\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yrX43gwPJDL-"
      },
      "source": [
        "#### Compile, train, and evaluate the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mVfI_1EoJDL_"
      },
      "source": [
        "# Compile the model with a binary cross-entropy loss\n",
        "\n",
        "model.compile(loss = 'binary_crossentropy', metrics = ['accuracy'], optimizer='adam')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AvR-O7wGJDMC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a6e691b-dbfa-4ba0-8408-b3a8b3ed97f2"
      },
      "source": [
        "# Train the model using .fit(), savng its history\n",
        "\n",
        "history = model.fit(x_train, y_train, epochs=5, batch_size=32, validation_data=(x_test, y_test), validation_steps=20)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.6917 - accuracy: 0.5190 - val_loss: 0.6836 - val_accuracy: 0.5781\n",
            "Epoch 2/5\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 0.6770 - accuracy: 0.6580 - val_loss: 0.6515 - val_accuracy: 0.7297\n",
            "Epoch 3/5\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 0.6403 - accuracy: 0.7484 - val_loss: 0.6011 - val_accuracy: 0.7641\n",
            "Epoch 4/5\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 0.5873 - accuracy: 0.7906 - val_loss: 0.5564 - val_accuracy: 0.7656\n",
            "Epoch 5/5\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 0.5401 - accuracy: 0.8106 - val_loss: 0.5101 - val_accuracy: 0.7953\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ind0d_gvJDMG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 354
        },
        "outputId": "8b338c5a-10c0-42a3-9142-2fa49521938e"
      },
      "source": [
        "# Plot the training and validation accuracy\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.style.use('ggplot')\n",
        "\n",
        "history_dict = history.history\n",
        "\n",
        "acc      = history_dict['accuracy']\n",
        "val_acc  = history_dict['val_accuracy']\n",
        "loss     = history_dict['loss']\n",
        "val_loss = history_dict['val_loss']\n",
        "\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "plt.figure(figsize=(14,5))\n",
        "plt.plot(epochs, acc, marker='.', label='Training acc')\n",
        "plt.plot(epochs, val_acc, marker='.', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Classification accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.ylim(0, 1);"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1008x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MHcNqGnWJDMH"
      },
      "source": [
        "#### The TensorFlow embedding projector\n",
        "\n",
        "The Tensorflow embedding projector can be found [here](https://projector.tensorflow.org/)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZVP4G9X0JDMH"
      },
      "source": [
        "# Retrieve the embedding layer's weights from the trained model\n",
        "\n",
        "weights = model.layers[1].get_weights()[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yHd29nfZJDMJ"
      },
      "source": [
        "# Save the word Embeddings to tsv files\n",
        "# Two files: \n",
        "#     one contains the embedding labels (meta.tsv),\n",
        "#     one contains the embeddings (vecs.tsv)\n",
        "\n",
        "import io\n",
        "from os import path\n",
        "\n",
        "out_v = io.open(path.join('/content/drive/MyDrive', 'vecs.tsv'), 'w', encoding='utf-8')\n",
        "out_m = io.open(path.join('/content/drive/MyDrive', 'meta.tsv'), 'w', encoding='utf-8')\n",
        "\n",
        "k = 0\n",
        "\n",
        "for word, token in imdb_word_index.items():\n",
        "    if k != 0:\n",
        "        out_m.write('\\n')\n",
        "        out_v.write('\\n')\n",
        "    \n",
        "    out_v.write('\\t'.join([str(x) for x in weights[token]]))\n",
        "    out_m.write(word)\n",
        "    k += 1\n",
        "    \n",
        "out_v.close()\n",
        "out_m.close()\n",
        "# beware large collections of embeddings!"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Ti4kMquJDML"
      },
      "source": [
        "---\n",
        "<a id=\"coding_tutorial_5\"></a>\n",
        "## Recurrent neural network layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9hrm6Q2jJDMM"
      },
      "source": [
        "#### Initialize and pass an input to a SimpleRNN layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tM7uSwkQJDMR"
      },
      "source": [
        "# Create a SimpleRNN layer and test it\n",
        "\n",
        "simple_rnn = tf.keras.layers.SimpleRNN(units = 16)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U_YJUyrEJDMT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87273299-1ffa-4a51-ff43-4757c9019bf3"
      },
      "source": [
        "# Note that only the final cell output is returned\n",
        "\n",
        "sequence = tf.constant([[[1.,1.],[2.,2.],[-56.,100.]]])\n",
        "\n",
        "layer_output = simple_rnn(sequence)\n",
        "layer_output"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 16), dtype=float32, numpy=\n",
              "array([[-0.99999976, -0.9892345 ,  0.99999976, -0.99999976,  0.99999976,\n",
              "        -0.99999976,  0.99999976, -0.99999976,  0.99983025,  0.99999976,\n",
              "         0.99999976, -0.99999976,  0.9981606 , -0.99999976, -0.99999976,\n",
              "         0.99999976]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r_rwdZtmJDMV"
      },
      "source": [
        "#### Load and transform the IMDB review sentiment dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qvAtycIpH1aA"
      },
      "source": [
        "# A function to load and preprocess the IMDB dataset\n",
        "\n",
        "def get_and_pad_imdb_dataset(num_words=10000, maxlen=None, index_from=2):\n",
        "    from tensorflow.keras.datasets import imdb\n",
        "\n",
        "    # Load the reviews\n",
        "    (x_train, y_train), (x_test, y_test) = imdb.load_data(path='imdb.npz',\n",
        "                                                          num_words=num_words,\n",
        "                                                          skip_top=0,\n",
        "                                                          maxlen=maxlen,\n",
        "                                                          start_char=1,\n",
        "                                                          oov_char=2,\n",
        "                                                          index_from=index_from)\n",
        "\n",
        "    x_train = tf.keras.preprocessing.sequence.pad_sequences(x_train,\n",
        "                                                        maxlen=None,\n",
        "                                                        padding='pre',\n",
        "                                                        truncating='pre',\n",
        "                                                        value=0)\n",
        "    \n",
        "    x_test = tf.keras.preprocessing.sequence.pad_sequences(x_test,\n",
        "                                                           maxlen=None,\n",
        "                                                           padding='pre',\n",
        "                                                           truncating='pre',\n",
        "                                                           value=0)\n",
        "    return (x_train, y_train), (x_test, y_test)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "49rJuSFmJDMV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf97d7f7-8200-4653-8d68-3df890095a41"
      },
      "source": [
        "# Load the dataset\n",
        "\n",
        "(x_train,y_train), (x_test, y_test) = get_and_pad_imdb_dataset(maxlen=250)\n"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/imdb.py:159: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/imdb.py:160: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XwUHcFKwH4wh"
      },
      "source": [
        "# A function to get the dataset word index\n",
        "\n",
        "def get_imdb_word_index(num_words=10000, index_from=2):\n",
        "    imdb_word_index = tf.keras.datasets.imdb.get_word_index(\n",
        "                                        path='imdb_word_index.json')\n",
        "    imdb_word_index = {key: value + index_from for\n",
        "                       key, value in imdb_word_index.items() if value <= num_words-index_from}\n",
        "    return imdb_word_index"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KfyqmfOXJDMX"
      },
      "source": [
        "# Get the word index using get_imdb_word_index()\n",
        "\n",
        "imdb_word_index = get_imdb_word_index()"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jR7y1e-xJDMd"
      },
      "source": [
        "#### Create a recurrent neural network model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tym76m2dIVOZ"
      },
      "source": [
        "# Get the maximum index value\n",
        "\n",
        "max_index_value = max(imdb_word_index.values())\n",
        "embedding_dim = 16"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2tO953-oJDMd"
      },
      "source": [
        "# Using Sequential, build the model:\n",
        "# 1. Embedding.\n",
        "# 2. LSTM.\n",
        "# 3. Dense.\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "                     tf.keras.layers.Embedding(input_dim=max_index_value+1, output_dim= embedding_dim, mask_zero=True),\n",
        "                     tf.keras.layers.LSTM(units = 16),\n",
        "                     tf.keras.layers.Dense(units = 1, activation='sigmoid')\n",
        "])"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v076l5CUJDMf"
      },
      "source": [
        "#### Compile and fit the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iRRXW5mPJDMg"
      },
      "source": [
        "# Compile the model with binary cross-entropy loss\n",
        "\n",
        "model.compile(loss = 'binary_crossentropy', metrics = ['accuracy'], optimizer = 'adam')"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "216PeHZFJDMi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3831addf-339e-42fa-bbf3-2f6cdb59ed29"
      },
      "source": [
        "# Fit the model and save its training history\n",
        "\n",
        "history = model.fit(x_train, y_train, epochs = 3, validation_data=(x_test, y_test))"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "536/536 [==============================] - 276s 509ms/step - loss: 0.1235 - accuracy: 0.9595 - val_loss: 0.3541 - val_accuracy: 0.8675\n",
            "Epoch 2/3\n",
            "536/536 [==============================] - 266s 496ms/step - loss: 0.0905 - accuracy: 0.9733 - val_loss: 0.4320 - val_accuracy: 0.8634\n",
            "Epoch 3/3\n",
            "536/536 [==============================] - 265s 494ms/step - loss: 0.0707 - accuracy: 0.9783 - val_loss: 0.4394 - val_accuracy: 0.8600\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1NVXF1TSJDMj"
      },
      "source": [
        "#### Plot learning curves"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ms9VW07lJDMk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 354
        },
        "outputId": "37bf9b7d-5af1-4972-c92c-6e2c0e7b41f1"
      },
      "source": [
        "# Plot the training and validation accuracy\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.style.use('ggplot')\n",
        "\n",
        "history_dict = history.history\n",
        "\n",
        "acc      = history_dict['accuracy']\n",
        "val_acc  = history_dict['val_accuracy']\n",
        "loss     = history_dict['loss']\n",
        "val_loss = history_dict['val_loss']\n",
        "\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "plt.figure(figsize=(14,5))\n",
        "plt.plot(epochs, acc, marker='.', label='Training acc')\n",
        "plt.plot(epochs, val_acc, marker='.', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Classification accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.ylim(0, 1);"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1008x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6AAyEd6wJDMm"
      },
      "source": [
        "#### Make predictions with the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sk9CHYLiJDMo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "a642b99e-39e1-458f-a290-456dd5e6c095"
      },
      "source": [
        "# View the first test data example sentence\n",
        "# (invert the word index)\n",
        "\n",
        "inv_imdb_word_index = {val : key for key, val in imdb_word_index.items()}\n",
        "first_review_list = [inv_imdb_word_index[index] for index in x_test[0] if index > 2]\n",
        "first_review = ' '.join(first_review_list)\n",
        "first_review"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"please give this one a miss br br and the rest of the cast rendered terrible performances the show is flat flat flat br br i don't know how michael madison could have allowed this one on his plate he almost seemed to know this wasn't going to work out and his performance was quite so all you madison fans give this a miss\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Blf6in2dJDMs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "115b8ffd-efd1-462b-febd-ff8d8b9eeb53"
      },
      "source": [
        "# Get the model prediction using model.predict()\n",
        "\n",
        "model.predict(x_test[None,0,:])"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.01034679]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SCyKBsZHJDMt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "465b15db-628e-43a2-ce45-28b60bd460d4"
      },
      "source": [
        "# Get the corresponding label\n",
        "\n",
        "y_test[0]"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RpaI83PlJDMv"
      },
      "source": [
        "---\n",
        "<a id=\"coding_tutorial_6\"></a>\n",
        "## Stacked RNNs and the Bidirectional wrapper"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Qr4kOevKRt8"
      },
      "source": [
        "#### Load and transform the IMDb review sentiment dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i06LdJiXKRt9"
      },
      "source": [
        "# A function to load and preprocess the IMDB dataset\n",
        "\n",
        "def get_and_pad_imdb_dataset(num_words=10000, maxlen=None, index_from=2):\n",
        "    from tensorflow.keras.datasets import imdb\n",
        "\n",
        "    # Load the reviews\n",
        "    (x_train, y_train), (x_test, y_test) = imdb.load_data(path='imdb.npz',\n",
        "                                                          num_words=num_words,\n",
        "                                                          skip_top=0,\n",
        "                                                          maxlen=maxlen,\n",
        "                                                          start_char=1,\n",
        "                                                          oov_char=2,\n",
        "                                                          index_from=index_from)\n",
        "\n",
        "    x_train = tf.keras.preprocessing.sequence.pad_sequences(x_train,\n",
        "                                                        maxlen=None,\n",
        "                                                        padding='pre',\n",
        "                                                        truncating='pre',\n",
        "                                                        value=0)\n",
        "    \n",
        "    x_test = tf.keras.preprocessing.sequence.pad_sequences(x_test,\n",
        "                                                           maxlen=None,\n",
        "                                                           padding='pre',\n",
        "                                                           truncating='pre',\n",
        "                                                           value=0)\n",
        "    return (x_train, y_train), (x_test, y_test)"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EjA8JlQVKRuB"
      },
      "source": [
        "# Load the dataset\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7iBFGx9_KRuD"
      },
      "source": [
        "# A function to get the dataset word index\n",
        "\n",
        "def get_imdb_word_index(num_words=10000, index_from=2):\n",
        "    imdb_word_index = tf.keras.datasets.imdb.get_word_index(\n",
        "                                        path='imdb_word_index.json')\n",
        "    imdb_word_index = {key: value + index_from for\n",
        "                       key, value in imdb_word_index.items() if value <= num_words-index_from}\n",
        "    return imdb_word_index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "29lcV0UGKRuF"
      },
      "source": [
        "# Get the word index using get_imdb_word_index()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lh_Vv9-5JDM1"
      },
      "source": [
        "#### Build stacked and bidirectional recurrent models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k6Sy-gMyLLEI"
      },
      "source": [
        "# Get the maximum index value and specify an embedding dimension\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "89yWIAFdJDM1"
      },
      "source": [
        "# Using Sequential, build a stacked LSTM model via return_sequences=True\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D-34ZWvRJDM3"
      },
      "source": [
        "# Using Sequential, build a bidirectional RNN with merge_mode='sum'\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mSpOIOCmJDM4"
      },
      "source": [
        "# Create a model featuring both stacked recurrent layers and a bidirectional layer\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H3srEhqCJDM7"
      },
      "source": [
        "#### Compile and fit the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k5Dy_C6-JDM7"
      },
      "source": [
        "# Compile the model\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Er8atiBoJDM9"
      },
      "source": [
        "# Train the model, saving its history\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uLOLtBKwJDNA"
      },
      "source": [
        "# Plot the training and validation accuracy\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.style.use('ggplot')\n",
        "\n",
        "history_dict = history.history\n",
        "\n",
        "acc      = history_dict['accuracy']\n",
        "val_acc  = history_dict['val_accuracy']\n",
        "loss     = history_dict['loss']\n",
        "val_loss = history_dict['val_loss']\n",
        "\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "plt.figure(figsize=(14,5))\n",
        "plt.plot(epochs, acc, marker='.', label='Training acc')\n",
        "plt.plot(epochs, val_acc, marker='.', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Classification accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.ylim(0, 1);"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}